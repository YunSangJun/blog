<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.0">Jekyll</generator><link href="http://localhost:4000/blog/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/blog/" rel="alternate" type="text/html" /><updated>2019-09-23T02:30:43+09:00</updated><id>http://localhost:4000/blog/</id><title type="html">SJ Tech Blog</title><subtitle>Software &amp; Cloud Engineer 입니다. Kubernetes, Cloud 및 DevOps 관련 기술에 관심이 있습니다.</subtitle><author><name>SJ</name></author><entry><title type="html">Istio Study #2.4 Isiio observability, resiliency, traffic routing</title><link href="http://localhost:4000/blog/istio/2019/09/22/istio-study-2.4.html" rel="alternate" type="text/html" title="Istio Study #2.4 Isiio observability, resiliency, traffic routing" /><published>2019-09-22T00:00:00+09:00</published><updated>2019-09-22T00:00:00+09:00</updated><id>http://localhost:4000/blog/istio/2019/09/22/istio-study-2.4</id><content type="html" xml:base="http://localhost:4000/blog/istio/2019/09/22/istio-study-2.4.html">&lt;h2 id=&quot;overview&quot;&gt;Overview&lt;/h2&gt;

&lt;p&gt;지금까지 두 개의 서비스를 배포했습니다. 하지만 외부에서 서비스로 접속할 수 있는 방법이 없습니다. 
Kubernetes 환경에서는 일반적으로 Ingress resource 또는 API Gateway(e.g Gloo)를 사용합니다.
Istio를 사용한다면 Istio Gateway를 사용할 수 있습니다.&lt;/p&gt;

&lt;p class=&quot;tip-title&quot;&gt;참고&lt;/p&gt;
&lt;p class=&quot;tip-content&quot;&gt;
Ingress resource는 Enterprise workload에 적합하지 않습니다. 
그 이유와 Istio Gateway가 이 문제를 어떻게 해결할 수 있는지에 대해서는 추후 살펴보겠습니다. 
&lt;/p&gt;

&lt;h2 id=&quot;1istio-gateway-배포하기&quot;&gt;1.Istio Gateway 배포하기&lt;/h2&gt;

&lt;p&gt;apigateway 서비스를 외부에서 접속가능하도록 노출시키기 위해 Istio Gateway를 배포하겠습니다.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ kubectl create -f chapters/chapter2/ingress-gateway.yaml
gateway.networking.istio.io/coolstore-gateway created
virtualservice.networking.istio.io/apigateway-virtualservice created
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Public cloud 환경에서 Kubernetes cluster를 운영하고 있다면 public cloud의 외부 접속 경로를 아래와 같이 확인할 수 있습니다.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ URL=$(kubectl -n istio-system get svc istio-ingressgateway -o jsonpath='{.status.loadBalancer.ingress[0].ip}')
$ echo $URL
xxx.xxx.xxx.xxx
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;이제 외부에서 apigateway 서비스를 호출합니다.
정상적으로 동작한다면 이전과 마찬가지로 상품 목록이 응답으로 반환됩니다.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ curl $URL/api/catalog
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;2istio-observability&quot;&gt;2.Istio observability&lt;/h2&gt;

&lt;p&gt;Istio proxy는 요청을 발신/수신하는 양쪽 모두에 위치해 있기 때문에 많은 양의 telemetry를 수집할 수 있습니다.&lt;/p&gt;

&lt;h3 id=&quot;top-level-metrics&quot;&gt;Top Level Metrics&lt;/h3&gt;

&lt;p&gt;먼저 Grafana에 접속해보겠습니다.
Grafana pod로 port forwarding을 설정합니다.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ GRAFANA=$(kubectl -n istio-system get pod | grep -i running | \
grep grafana | cut -d ' ' -f 1)
$ kubectl port-forward -n istio-system $GRAFANA 8080:3000
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;웹 브라우저에서 &lt;code class=&quot;highlighter-rouge&quot;&gt;localhost:8080&lt;/code&gt;로 접속합니다.
가장 먼저 Istio dashboard의 리스트를 확인할 수 있습니다.
&lt;img src=&quot;/blog/assets/images/kubernetes/istio/istio-study-2.4-001.png&quot; alt=&quot;&quot; /&gt;
[출처: Istio in Action MEAP Edition]&lt;/p&gt;

&lt;p&gt;리스트에서 Istio Service Dashboard를 살펴보겠습니다.
Service combo box에서 apigateway.istioinaction.svc.cluster.local를 선택합니다.
하단의 그래프에서 Client Request Volume과 Client Success Rate metric을 확인할 수 있습니다.
이 값은 보통 비어있거나 “N/A” 상태입니다. 
&lt;img src=&quot;/blog/assets/images/kubernetes/istio/istio-study-2.4-002.png&quot; alt=&quot;&quot; /&gt;
[출처: Istio in Action MEAP Edition]&lt;/p&gt;

&lt;p&gt;터미널에서 서비스에 traffic을 몇 차례 요청합니다.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ while true; do curl $URL/api/catalog; sleep .5; done
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Grafana dashboard로 돌아와보면 아래와 같이 metric에 변화가 있는 것을 확인할 수 있습니다. 
서비스 호출이 100% 성공했다는 것을 알 수 있고 P50, P90, 및 P99 tail latencies를 볼 수 있습니다.
&lt;img src=&quot;/blog/assets/images/kubernetes/istio/istio-study-2.4-003.png&quot; alt=&quot;&quot; /&gt;
[출처: Istio in Action MEAP Edition]&lt;/p&gt;

&lt;p&gt;여기서 중요한 점은 metric을 확인하기 위해 application 코드에 아무것도 추가하지 않았다는 것입니다.&lt;/p&gt;

&lt;h3 id=&quot;distributed-tracing-with-opentracing&quot;&gt;Distributed Tracing With Opentracing&lt;/h3&gt;

&lt;p&gt;이번에는 분산 tracing을 다뤄보겠습니다. Istio는 opentracing을 구현한 Jaeger를 기본으로 설치합니다.&lt;/p&gt;

&lt;p&gt;Jaeger에 접속하기 위해 istio-tracing pod로 port forwarding을 합니다.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ TRACING=$(kubectl -n istio-system get pod | grep istio-tracing | cut -d ' ' -f 1)
$ kubectl port-forward -n istio-system $TRACING 8181:16686
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;웹 브라우저에서 &lt;code class=&quot;highlighter-rouge&quot;&gt;http://localhost:8181/&lt;/code&gt;에 접속합니다.
Service combo box에서 istio-ingressgateway를 선택합니다.
그리고 Find Traces 버튼을 선택합니다.
&lt;img src=&quot;/blog/assets/images/kubernetes/istio/istio-study-2.4-004.png&quot; alt=&quot;&quot; /&gt;
[출처: Istio in Action MEAP Edition]&lt;/p&gt;

&lt;p&gt;만약 아무 것도 나타나지 않는다면 traffic을 발생시키기 위해 서비스를 몇 회 호출합니다.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ while true; do curl $URL/api/catalog; sleep .5; done
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;다시 Jaeger dashboard로 돌아와서 Find Traces 버튼을 선택합니다.
분산 tracing span이 생성된 것을 확인할 수 있습니다. 
&lt;img src=&quot;/blog/assets/images/kubernetes/istio/istio-study-2.4-005.png&quot; alt=&quot;&quot; /&gt;
[출처: Istio in Action MEAP Edition]&lt;/p&gt;

&lt;p&gt;Span을 선택하면 특정 요청에 대해 상세한 정보를 확인할 수 있습니다.
&lt;img src=&quot;/blog/assets/images/kubernetes/istio/istio-study-2.4-006.png&quot; alt=&quot;&quot; /&gt;
[출처: Istio in Action MEAP Edition]&lt;/p&gt;

&lt;h2 id=&quot;3istio-resiliency&quot;&gt;3.Istio resiliency&lt;/h2&gt;

&lt;p&gt;예제 소스코드의 아래 스크립트를 실행하면 모든 요청이 HTTP 500 에러가 발생하도록 설정됩니다.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ ./bin/chaos.sh 500 100
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;실제로 apigateway 서비스를 호출하면 500에러가 발생하는것을 확인할 수 있습니다.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ curl -v $URL/api/catalog
* Trying 192.168.64.67...
* TCP_NODELAY set
* Connected to 192.168.64.67 (192.168.64.67) port 31380 (#0)
&amp;gt; GET /api/catalog HTTP/1.1
&amp;gt; Host: 192.168.64.67:31380
&amp;gt; User-Agent: curl/7.54.0
&amp;gt; Accept: */*
&amp;lt; HTTP/1.1 500 Internal Server Error
&amp;lt; content-type: text/plain; charset=utf-8
&amp;lt; x-content-type-options: nosniff
&amp;lt; date: Wed, 17 Apr 2019 00:13:16 GMT
&amp;lt; content-length: 30
&amp;lt; x-envoy-upstream-service-time: 4
&amp;lt; server: istio-envoy
&amp;lt;
error calling Catalog service
* Connection #0 to host 192.168.64.67 left intact
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;이번에는 apigateway 서비스를 호출할 떄 50%의 에러가 발생하도록 설정하겠습니다.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ ./bin/chaos.sh 500 50
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;apigateway 서비스를 반복적으로 호출해보면 성공 또는 실패 메세지가 간헐적으로 발생하는 것을 확인할 수 있습니다.
호출 실패의 경우 apigateway 서비스가 catalog 서비스를 호출할 때 발생합니다.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ while true; do curl $URL/api/catalog; \
sleep .5; done
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;이제 Istio가 어떻게 apigateway와 catalog 서비스간의 통신을 더 복원력있게 만들 수 있는지 확인해보겠습니다.&lt;/p&gt;

&lt;p&gt;먼저 Istio의 VirtualService 리소스를 살펴보겠습니다.
VirtualService는 서비스간의 상호작용을 정의합니다.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
 name: catalog
spec:
 hosts:
 - catalog
 http:
 - route:
 - destination:
 host: catalog
 retries:
 attempts: 3
 perTryTimeout: 2s
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;이제 위에서 살펴본 VirtualService 리소스를 배포합니다.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ kubectl apply -f chapters/chapter2/catalog-virtualservice.yaml
virtualservice.networking.istio.io/catalog created
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;apigateway 서비스를 반복적으로 호출해보면 실패 메세지가 더 이상 발생하지 않는 것을 확인할 수 있습니다.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ while true; do curl $URL/api/catalog; \
sleep .5; done
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;여기서 중요한 점은 application 코드를 수정하지 않고 서비스간 통신을 더 복원력있게 만들었다는 점입니다.&lt;/p&gt;

&lt;h2 id=&quot;4istio-traffic-routing&quot;&gt;4.Istio traffic routing&lt;/h2&gt;</content><author><name>sj</name></author><category term="istio" /><category term="servicemesh" /><category term="kubernetes" /><summary type="html">Overview</summary></entry><entry><title type="html">Istio Study #2.3 Service Mesh에 첫 번째 application 배포하기</title><link href="http://localhost:4000/blog/istio/2019/09/22/istio-study-2.3.html" rel="alternate" type="text/html" title="Istio Study #2.3 Service Mesh에 첫 번째 application 배포하기" /><published>2019-09-22T00:00:00+09:00</published><updated>2019-09-22T00:00:00+09:00</updated><id>http://localhost:4000/blog/istio/2019/09/22/istio-study-2.3</id><content type="html" xml:base="http://localhost:4000/blog/istio/2019/09/22/istio-study-2.3.html">&lt;h2 id=&quot;overview&quot;&gt;Overview&lt;/h2&gt;

&lt;p&gt;새로운 스타트업 Conference Outfitters가 웹 사이트와 재고 및 결제를 지원하는 시스템을 개편하고 있습니다.
그들은 Kubernetes를 다음과 같이 사용하기로 결정했습니다.
배포 플랫폼의 및 응용 프로그램을 특정 클라우드 공급 업체가 아닌 Kubernetes API에 구축하려고 합니다.
그들은 서비스간 통신의 몇 가지 문제를 해결하려하고 헤드 아키텍트가 Istio에 대해 알게되었을 때 그것을 활용하기로 결정했습니다.&lt;/p&gt;

&lt;p&gt;Conference Outfitter의 application은 일반적인 온라인 웹 스토어입니다. 매장을 구성하는 구성 요소를 살펴 보겠습니다.
먼저 Istio의 기능을 살펴보기 위해 구성 요소의 작은 하위 집합에 중점을 두겠습니다. 
웹 스토어는 AngularJS 및 NodeJS로 만든 web-facing 사용자 인터페이스로 구성됩니다.
이것은 backend의 catalog, inventory 서비스를 관리하는 gateway 서비스와 통신합니다.
첫 번째 예제에서는 gateway와 catalog 서비스만 배포합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/images/kubernetes/istio/istio-study-2.3-001.png&quot; alt=&quot;&quot; /&gt;
[출처: Istio in Action MEAP Edition]&lt;/p&gt;

&lt;h2 id=&quot;1예제-소스코드-준비&quot;&gt;1.예제 소스코드 준비&lt;/h2&gt;

&lt;p&gt;이 예제의 소스코드를 &lt;a href=&quot;https://github.com/istioinaction/book-source-code&quot;&gt;book-source-code github&lt;/a&gt;에서 다운로드합니다.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git clone https://github.com/istioinaction/book-source-code.git
cd book-source-code
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;book-source-code 디렉토리의 아래 경로에서 catalog 서비스를 조회해봅니다.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ cat services/catalog/kubernetes/catalog.yaml
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: catalog
  name: catalog
spec:
  ports:
  - name: http
    port: 80
    protocol: TCP
    targetPort: 3000
  selector:
    app: catalog
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: catalog
    version: v1
  name: catalog
spec:
  replicas: 1
  selector:
    matchLabels:
      app: catalog
      version: v1
  template:
    metadata:
      labels:
        app: catalog
        version: v1
    spec:
      containers:
      - env:
        - name: KUBERNETES_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        image: istioinaction/catalog:latest
        imagePullPolicy: IfNotPresent
        name: catalog
        ports:
        - containerPort: 3000
          name: http
          protocol: TCP
        securityContext:
          privileged: false
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;2배포-준비&quot;&gt;2.배포 준비&lt;/h2&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;istioinaction&lt;/code&gt; namespace를 생성하고 기본 context를 설정합니다.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ kubectl create namespace istioinaction
$ kubectl config set-context $(kubectl config current-context) \
 --namespace=istioinaction
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Application을 배포하기 전에 Istio service proxy를 injection 해야합니다.
아래와 같이 istioctl를 통해 service proxy를 injection 할 수 있습니다.
결과를 확인해보면 istio proxy container 및 설정이 있는 것을 확인할 수 있습니다.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ istioctl kube-inject -f services/catalog/kubernetes/catalog.yaml
   ...
   image: docker.io/istio/proxyv2:1.2.2
   imagePullPolicy: IfNotPresent
   name: istio-proxy
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;3catalog-서비스-배포&quot;&gt;3.Catalog 서비스 배포&lt;/h2&gt;

&lt;p&gt;이제 예제의 catalog 서비스를 배포해보겠습니다.
istioctl를 통해 service proxy를 injection하고 그 결과를 바로 kubectl을 통해 배포합니다.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ kubectl create -f &amp;lt;(istioctl kube-inject \
-f services/catalog/kubernetes/catalog.yaml)

service/catalog created
deployment.apps/catalog created
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;배포 결과를 조회해봅니다. 
최초 PodInitializing 상태에서 일정 시간이 지나면 Running 상태로 변경됩니다.
실제 catlog 서비스의 컨테이너는 1개이지만 service proxy가 injection되었기 때문에 2개의 컨테이너를 확인할 수 있습니다.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ kubectl get pod
NAME                       READY   STATUS            RESTARTS   AGE
catalog-66f64d84df-8l6rp   0/2     PodInitializing   0          50s

...

$ kubectl get po
NAME                       READY   STATUS    RESTARTS   AGE
catalog-66f64d84df-8l6rp   2/2     Running   0          2m47s
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;아래 명령을 실행해서 catalog 서비스가 정상적으로 호출되는지 요청을 해보겠습니다.
정상적으로 동작한다면 아래와 같이 상품 목록을 응답으로 반환해줍니다.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ kubectl run -i --rm --restart=Never dummy \
--image=dockerqa/curl:ubuntu-trusty --command \
-- sh -c 'curl -s catalog/items'
[
 {
 &quot;id&quot;: 0,
 &quot;color&quot;: &quot;teal&quot;,
 &quot;department&quot;: &quot;Clothing&quot;,
 &quot;name&quot;: &quot;Small Metal Shoes&quot;,
 &quot;price&quot;: &quot;232.00&quot;
 },
 {
 &quot;id&quot;: 1,
 &quot;color&quot;: &quot;turquoise&quot;,
 &quot;department&quot;: &quot;Toys&quot;,
 &quot;name&quot;: &quot;Generic Plastic Sausages&quot;,
 &quot;price&quot;: &quot;144.00&quot;
 },
 {
 &quot;id&quot;: 2,
 &quot;color&quot;: &quot;purple&quot;,
 &quot;department&quot;: &quot;Jewelery&quot;,
 &quot;name&quot;: &quot;Intelligent Metal Bike&quot;,
 &quot;price&quot;: &quot;484.00&quot;
 },
...
]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;4api-gateway-서비스-배포&quot;&gt;4.API Gateway 서비스 배포&lt;/h2&gt;

&lt;p&gt;다음으로 backend 서비스의 facade를 제공하는 API Gateway 서비스를 배포해보겠습니다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ kubectl create -f &amp;lt;(istioctl kube-inject \
-f services/apigateway/kubernetes/apigateway.yaml)

service/apigateway created
deployment.extensions/apigateway created
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;이전에 배포한 catalog 서비스와 함께 apigateway pod를 확인할 수 있습니다.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ kubectl get pod
NAME                          READY   STATUS    RESTARTS   AGE
apigateway-85d7785b48-h9wfd   2/2     Running   0          3m45s
catalog-66f64d84df-8l6rp      2/2     Running   0          14m
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;apigateway 서비스가 정상적으로 호출되는지 확인합니다.
정상적으로 동작한다면 catalog 서비스를 호출했을 때와 마찬가지로 상품 목록을 응답으로 반환해줍니다.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ kubectl run -i --rm --restart=Never dummy --image=dockerqa/curl:ubuntu-trusty \
--command -- sh -c 'curl -s apigateway/api/catalog'
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;지금까지 catalog 및 apigateway 서비스를 Istio service proxy와 함께 배포했습니다.
각 서비스는 자신의 proxy를 가지고 있고 서비스 간의 모든 traffic은 이 proxy를 통해서 전달됩니다.
&lt;img src=&quot;/blog/assets/images/kubernetes/istio/istio-study-2.3-002.png&quot; alt=&quot;&quot; /&gt;
[출처: Istio in Action MEAP Edition]&lt;/p&gt;</content><author><name>sj</name></author><category term="istio" /><category term="servicemesh" /><category term="kubernetes" /><summary type="html">Overview</summary></entry><entry><title type="html">Istio Study #2.2 Isio Control Plane 알아보기</title><link href="http://localhost:4000/blog/istio/2019/09/21/istio-study-2.2.html" rel="alternate" type="text/html" title="Istio Study #2.2 Isio Control Plane 알아보기" /><published>2019-09-21T00:00:00+09:00</published><updated>2019-09-21T00:00:00+09:00</updated><id>http://localhost:4000/blog/istio/2019/09/21/istio-study-2.2</id><content type="html" xml:base="http://localhost:4000/blog/istio/2019/09/21/istio-study-2.2.html">&lt;p&gt;&lt;a href=&quot;/blog/istio/2019/09/21/istio-study-2.1.html&quot;&gt;2.1 Kubernetes에 Istio 배포하기&lt;/a&gt;
에서 Istio의 control plane의 모든 구성 요소를 설치했습니다.&lt;/p&gt;

&lt;p&gt;Control plane은 사용자에게 아래와 같이 service mesh를 제어, 관찰, 관리, 설정 할 수 있는 방법을 제공합니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;라우팅, 복원&lt;/li&gt;
  &lt;li&gt;Data plane에 로컬화된 설정을 제공하기 위한 API 제공&lt;/li&gt;
  &lt;li&gt;Service discovery&lt;/li&gt;
  &lt;li&gt;할당량을 설정 및 사용량을 제한&lt;/li&gt;
  &lt;li&gt;사용 정책 설정&lt;/li&gt;
  &lt;li&gt;인증서 발급 및 교체&lt;/li&gt;
  &lt;li&gt;Workload 식별&lt;/li&gt;
  &lt;li&gt;telemetry(원격 측정) 통합 수집&lt;/li&gt;
  &lt;li&gt;네트워크 접근 제어&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이러한 기능은 control plane의 각 구성 요소에 분산되어 있습니다.
이어서 핵심 구성 요소에 대해 더 살펴보겠습니다.&lt;/p&gt;

&lt;h2 id=&quot;1istio-pilot&quot;&gt;1.Istio Pilot&lt;/h2&gt;

&lt;p&gt;Istio Pilot은 사용자와 운영자가 service proxy를 data plane에 구성할 수 있게 해줍니다.&lt;/p&gt;

&lt;p&gt;Pilot은 플랫폼에 독립적이며 플랫폼 adapter를 사용해 플랫폼에 특화된 서비스를 사용합니다.
예를 들어, Kubernetes 플랫폼에서는 Kubernetes에서 제공하는 방식으로 service registration 및 discovery 서비스를 활용합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/images/kubernetes/istio/istio-study-2.2-001.png&quot; alt=&quot;&quot; /&gt;
[출처: Istio in Action MEAP Edition]&lt;/p&gt;

&lt;p&gt;Pilot의 설정을 통해 traffic 유입, 라우팅, 서비스 복원 등을 관리할 수 있습니다.
예를 들어, 요청 정보에 따라 어떤 버전의 서비스를 사용하는지 또는 배포를 할 때 버전간의 트래픽을 어떻게 이동하는지 등의 traffic을 관리할 수 있습니다.
또한 요청에 대한 timeout, retries, circuit break와 같은 서비스 복원을 관리할 수 있습니다.&lt;/p&gt;

&lt;p&gt;Istio는 기본적으로 Envoy를 service proxy로 사용합니다.
아래 예제에서 Pilot의 설정을 살펴보겠습니다.&lt;/p&gt;

&lt;p&gt;한 서비스가 catalog 서비스와 통신하려고 합니다.
traffic header 정보에 &lt;code class=&quot;highlighter-rouge&quot;&gt;x-dark-launch&lt;/code&gt;의 갑싱 &lt;code class=&quot;highlighter-rouge&quot;&gt;v2&lt;/code&gt;이면 catalog 서비스의 &lt;code class=&quot;highlighter-rouge&quot;&gt;v2&lt;/code&gt;로 라우팅을 하려합니다.
이 경우 Pilot의 설정을 아래와 같이 설정할 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/images/kubernetes/istio/istio-study-2.2-002.png&quot; alt=&quot;&quot; /&gt;
[출처: Istio in Action MEAP Edition]&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;매칭하려는 요청 조건&lt;/li&gt;
  &lt;li&gt;매칭하려는 요청 조건 상세&lt;/li&gt;
  &lt;li&gt;매칭된 경우 라우팅 목적지&lt;/li&gt;
  &lt;li&gt;매칭되지 않은 다른 경우 라우팅 목적지&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;이 설정을 Istio 환경에 적용하려면 아래와 같이 &lt;code class=&quot;highlighter-rouge&quot;&gt;Kubectl&lt;/code&gt; tool을 활용하면됩니다.
(catalog-service.yaml 파일에는 위에서 예로 든 설정이 저장되어 있습니다.)&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ kubectl create -f catalog-service.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;이 부분에 대한 좀 더 상세한 내용은 추후 살펴보기로 하겠습니다.&lt;/p&gt;

&lt;p class=&quot;tip-title&quot;&gt;참고&lt;/p&gt;
&lt;p class=&quot;tip-content&quot;&gt;
Istio의 VirtualService등의 리소스는 Kubernetes의 CRD(Custom
Resource Definitions)를 통해 구현되었습니다.
&lt;/p&gt;

&lt;p&gt;Istio는 &lt;code class=&quot;highlighter-rouge&quot;&gt;VirtualService&lt;/code&gt;와 같은 Istio 특화된 설정을 Envoy의 native 설정으로 변환합니다.
예를 들어, Istio Pilot은 위의 설정을 아래와 같은 data plane API 형태로 service proxy에 노출합니다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&quot;domains&quot;:[
   &quot;catalog.prod.svc.cluster.local&quot;
],
&quot;name&quot;:&quot;catalog.prod.svc.cluster.local:80&quot;,
&quot;routes&quot;:[
   {
      &quot;match&quot;:{
         &quot;headers&quot;:[
            {
               &quot;name&quot;:&quot;x-dark-lauch&quot;,
               &quot;value&quot;:&quot;v2&quot;
            }
         ],
         &quot;prefix&quot;:&quot;/&quot;
      },
      &quot;route&quot;:{
         &quot;cluster&quot;:&quot;outbound|80|v2|catalog.prod.svc.cluster.local&quot;,
         &quot;use_websocket&quot;:false
      }
   },
   {
      &quot;match&quot;:{
         &quot;prefix&quot;:&quot;/&quot;
      },
      &quot;route&quot;:{
         &quot;cluster&quot;:&quot;outbound|80|v1|catalog.prod.svc.cluster.local&quot;,
         &quot;use_websocket&quot;:false
      }
   }
]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p class=&quot;tip-title&quot;&gt;참고&lt;/p&gt;
&lt;p class=&quot;tip-content&quot;&gt;
위 data plane API는 Istio Pilot(Envoy's discovery APIs로 구현)에 의해 노출됩니다.
이 API를 통해 data plane은 중지나 재시작없이 구성을 동적으로 반영할 수 있습니다.
이 API는 *xDS*라고 하는데 추후 Envoy proxy를 다룰때 좀 더 상세히 살펴보겠습니다.
&lt;/p&gt;

&lt;h2 id=&quot;2ingress-및-egress-gateway&quot;&gt;2.Ingress 및 Egress gateway&lt;/h2&gt;

&lt;p&gt;Application 및 service는 cluster 외부의 application과 통신해야하는 경우가 있습니다.
예를 들어, 모놀리틱 앱, 상용 소프트웨어, 메세징 큐, 데이터베이스, 3rd pary 앱 등이 있습니다. 
운영자는 이런 traffic이 cluster로 들어오거나 나가는 것을 적절하게 구성해야합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/images/kubernetes/istio/istio-study-2.2-003.png&quot; alt=&quot;&quot; /&gt;
[출처: Istio in Action MEAP Edition]&lt;/p&gt;

&lt;p&gt;Istio에서 이런 기능을 제공하는 구성 요소는 istio-ingressgateway, istio-egressgateway라고 합니다.
이 두 가지 구성 요소는 Istio 설정을 이해할 수 있는 Envoy proxy 그 자체입니다.&lt;/p&gt;

&lt;p&gt;이것들은 기술적으로 control plane의 부분이 아니지만 service mesh에서 중요한 역할을 합니다.
data plane의 service proxy와 유사하게 구성되어 있으며
차이점은 application과 독립적이며 단순히 traffic이 들어오고 나가는 것만을 관리합니다.&lt;/p&gt;

&lt;p&gt;이 구성 요소에 대한 자세한 내용은 추후에 좀 더 살펴보겠습니다.&lt;/p&gt;

&lt;h2 id=&quot;3istio-citadel&quot;&gt;3.Istio Citadel&lt;/h2&gt;

&lt;p&gt;Istio service mesh에서 service proxy는 application 인스턴스와 함께 실행됩니다.
하나의 application이 다른 application을 호출할 때 송신 및 수신하는 application의 proxy들은 직접 통신합니다.&lt;/p&gt;

&lt;p&gt;Istio의 주요 특징 중 하나는 두 service간의 통신을 암호화 한다는 것입니다.
X.509 인증서를 사용해 traffic을 암호화합니다.
사실, 이 인증서에는 &lt;a href=&quot;https://spiffe.io/&quot;&gt;SPIFFE(Secure Production Identity Framework For Everyone)&lt;/a&gt;에 의해 Workload의 식별자가 삽입됩니다.
이것은 application이 어떤 인증서를 가지고 있지 않아도 강력한 mTLS(mutual Transport Layer Security)를 제공합니다.&lt;/p&gt;

&lt;p&gt;Istio Citadel은 위와 같은 보안을 다루는 구성 요소로 인증서의 증명, 발급, 마운트 및 교체를 처리합니다. 
이에 대한 상세한 내용은 Istio의 보안 부분을 다룰 때 좀 더 상세히 살펴보겠습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/images/kubernetes/istio/istio-study-2.2-004.png&quot; alt=&quot;&quot; /&gt;
[출처: Istio in Action MEAP Edition]&lt;/p&gt;

&lt;h2 id=&quot;4istio-mixer&quot;&gt;4.Istio Mixer&lt;/h2&gt;

&lt;p&gt;Istio의 Mixer는 service mesh의 주요 세 가지 기능을 다루는 control plane 구성 요소입니다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;telemetry(원격 측정) 수집&lt;/li&gt;
  &lt;li&gt;traffic, 인증 정책 정의 및 실행&lt;/li&gt;
  &lt;li&gt;할당량 관리, 사용량 제한&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Application은 메트릭, 로그, 추적 데이터 등의 정보를 수집하기 위한 백엔드 인프라 서비스와 통신해야하는 경우가 있습니다.
이런 application은 서비스간의 인증 및 정책 결정을 위해 다양한 시스템과 통신해야합니다.
일반적으로 이런 경우 하드 코딩된 API를 사용하거나 백엔드에서 제공하는 클라이언트를 사용합니다.
이런 통일되지 않는 통신 방식으로 인한 데이터 손실 및 오류는 서비스 전체의 오류로 이어질 수 있습니다.&lt;/p&gt;

&lt;p&gt;Istio Mixer는 이런 문제를 해결하기 위해 단일, 통일된 추상화를 사용합니다.
각 요청은 컨텍스트 및 세부 사항을 설명하는 속성 목록으로 표시됩니다.
예를 들어, &lt;code class=&quot;highlighter-rouge&quot;&gt;source.IP source.user request.path request.size&lt;/code&gt; 등은 요청을 설명하는 속성입니다. 
이 속성 및 속성의 처리는 Mixer 엔진의 핵심 기능입니다.&lt;/p&gt;

&lt;p&gt;Istio는 data plane을 통해 들어오는 각 요청에 대해 이러한 속성을 기록하고 이를 Mixer로 보냅니다.
Mixer가 이 속성을 수신하면, 이 요청에 대한 처리를 진행할지 telemetry 수집할지를 결정합니다.
Mixer는 아래 두 API를 통해 위 동작을 수행합니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Check&lt;/li&gt;
  &lt;li&gt;Report&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;check-api-with-istio-policy&quot;&gt;Check API With ISTIO-POLICY&lt;/h3&gt;

&lt;p&gt;Check API는 해당 요청이 예상 조건을 만족하는지, 진행 또는 거부해야하는지 여부에 따라 속성을 기반으로 유효성 검증 요청과 함께 인라인으로 호출됩니다.
Mixer는 속성 처리 엔진을 사용하여 속성을 정책 엔진 또는 API 관리 시스템과 같은 특정 백엔드에 대한 요청으로 변환합니다.
Mixer를 사용하면 3rd party에서 속성 처리에 사용하는 어댑터를 생성하고 속성을 백엔드 별 메시지로 작성할 수 있습니다.
이 백엔드 시스템은 긍정 또는 부정으로 응답할 수 있고 API에서 정해진대로 요청을 처리합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/images/kubernetes/istio/istio-study-2.2-005.png&quot; alt=&quot;&quot; /&gt;
[출처: Istio in Action MEAP Edition]&lt;/p&gt;

&lt;p&gt;아래는 Istio Policy 엔진으로 전송되는 속성 샘플입니다.
일반적으로 사용되는 배포 속성은 &lt;a href=&quot;https://istio.io/docs/reference/config/policy-and-telemetry/attribute-vocabulary/&quot;&gt;Attribute Vocabulary&lt;/a&gt; 에서 확인할 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/images/kubernetes/istio/istio-study-2.2-006.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/images/kubernetes/istio/istio-study-2.2-007.png&quot; alt=&quot;&quot; /&gt;
[출처: Istio in Action MEAP Edition]&lt;/p&gt;

&lt;h3 id=&quot;mixer-report-api-with-istio-telemetry&quot;&gt;MIXER Report API With ISTIO-TELEMETRY&lt;/h3&gt;

&lt;p&gt;Check API와 마찬가지로 Report API는 요청에 대한 속성을 전송하는데 사용됩니다.
그러나 Check API와 다르게 비동기적으로 호출되고 요청 경로 밖에 있습니다.&lt;/p&gt;

&lt;p&gt;Service proxy가 요청을 처리될때 그 요청의 속성은 proxy에 의해 일괄 처리되고 특정 요청이 들어올 때 또는 일정 시간 후에 Mixer로 전송됩니다.
예를 들어, 100개의 요청이 서비스로 유입되면 service proxy는 그 요청들의 속성을 일괄적으로 처리하고 Mixer로 전송합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/images/kubernetes/istio/istio-study-2.2-008.png&quot; alt=&quot;&quot; /&gt;
[출처: Istio in Action MEAP Edition]&lt;/p&gt;

&lt;p&gt;Control plane에 실제로 Mixer 구성 요소가 배포되어 있진 않습니다. 
Check, Report API는 서로 다른 런타임과 스케일링 조건을 가지기 때문에 분리되어 있습니다.
istio-policy는 Check API를 구현하고 istio-telemetry Report API를 구현합니다.&lt;/p&gt;

&lt;p class=&quot;tip-title&quot;&gt;참고&lt;/p&gt;
&lt;p class=&quot;tip-content&quot;&gt;
Check, Report API는 서로 분리되어 있지만 두 가지 API를 관리하는 Mixer 구성 요소는 하나입니다.
istio-policy, istio-telemetry deployment의 상세 내용을 보면 mixer contrainer를 동일하게 포함하는 것을 확인할 수 있습니다.
&lt;/p&gt;</content><author><name>sj</name></author><category term="istio" /><category term="servicemesh" /><category term="kubernetes" /><summary type="html">2.1 Kubernetes에 Istio 배포하기 에서 Istio의 control plane의 모든 구성 요소를 설치했습니다.</summary></entry><entry><title type="html">Istio Study #2.1 Kubernetes에 Istio 배포하기</title><link href="http://localhost:4000/blog/istio/2019/09/21/istio-study-2.1.html" rel="alternate" type="text/html" title="Istio Study #2.1 Kubernetes에 Istio 배포하기" /><published>2019-09-21T00:00:00+09:00</published><updated>2019-09-21T00:00:00+09:00</updated><id>http://localhost:4000/blog/istio/2019/09/21/istio-study-2.1</id><content type="html" xml:base="http://localhost:4000/blog/istio/2019/09/21/istio-study-2.1.html">&lt;p&gt;이 문서에서는 Istio와 샘플 앱을 배포해보겠습니다.&lt;/p&gt;

&lt;p&gt;Istio는 Kubernetes에 의존성이 없고 다양한 플랫폼을 지원합니다.&lt;/p&gt;

&lt;p&gt;Kubernetes는 Istio를 배포하기 가장 좋은 플랫폼이므로 이 환경에 배포해보겠습니다.&lt;/p&gt;

&lt;h2 id=&quot;1kubernetes준비하기&quot;&gt;1.Kubernetes 준비하기&lt;/h2&gt;

&lt;p&gt;Kubernetes Cluster를 minikube, cloud 환경을 활용해 준비합니다.&lt;/p&gt;

&lt;p&gt;이 문서에서는
&lt;a href=&quot;https://cloud.google.com/kubernetes-engine/docs/quickstart?hl=ko&quot;&gt;GKE(Google Kubernetes Engine)&lt;/a&gt;
을 활용했습니다. 구글 계정을 가지고 있다면 Credit을 받아 일정기간 무료로 사용할 수 있습니다.&lt;/p&gt;

&lt;p class=&quot;tip-title&quot;&gt;참고&lt;/p&gt;
&lt;p class=&quot;tip-content&quot;&gt;
이 문서에서는 Kubernetes `v1.13.7-gke.8` 버전을 사용했습니다.
&lt;/p&gt;

&lt;h2 id=&quot;2istio-다운로드&quot;&gt;2.Istio 다운로드&lt;/h2&gt;

&lt;p&gt;이제 Kubernetes 리소스를 활용하여 Istio를 Kubernetes Cluster에 배포해보겠습니다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/istio/istio/releases&quot;&gt;Istio release&lt;/a&gt;에 접속해서 원하는 버전을 선택하고
각자 환경에 맞는 OS의 release를 선택합니다.&lt;/p&gt;

&lt;p class=&quot;tip-title&quot;&gt;참고&lt;/p&gt;
&lt;p class=&quot;tip-content&quot;&gt;
이 문서에서는 1.2.2 버전을 사용했습니다.
&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;wget https://github.com/istio/istio/releases/download/1.2.2/istio-1.2.2-linux.tar.gz
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;다운로드 받은 파일에서 배포 파일을 추출합니다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;tar -xzf istio-1.2.2-linux.tar.gz
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;다음으로 배포 파일이 있는 디렉토리를 살펴보겠습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;bin: istioctl 실행 파일&lt;/li&gt;
  &lt;li&gt;install: istio 배포를 위한 스크립트 및 리소스 파일&lt;/li&gt;
  &lt;li&gt;sample: istio에 배포할 샘플 앱&lt;/li&gt;
  &lt;li&gt;tools: istio 테스트 세트&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ cd istio-1.2.2
$ ls -l
total 40
drwxr-xr-x  2 ...  4096 Jun 28 02:03 bin
drwxr-xr-x  6 ...  4096 Jun 28 02:03 install
...
drwxr-xr-x 16 ...  4096 Jun 28 02:03 samples
drwxr-xr-x  8 ...  4096 Jun 28 02:03 tools
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;istioctl이 정상 동작하는지 확인합니다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ ./bin/istioctl version
1.2.2
Error: unable to find any Istio pod in namespace istio-system
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;다음으로 istio를 설치하는데 문제가 없는지 검증합니다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ ./bin/istioctl verify-install
Checking the cluster to make sure it is ready for Istio installation...
Kubernetes-api
-----------------------
...
Install Pre-Check passed! The cluster is ready for Istio installation.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;3istio-구성-요소-설치하기&quot;&gt;3.Istio 구성 요소 설치하기&lt;/h2&gt;

&lt;p&gt;Istio를 설치할 때 권장하는 방법은 &lt;a href=&quot;https://helm.sh/&quot;&gt;Helm&lt;/a&gt;을 사용하는 것입니다.
Helm을 사용하면 Istio 구성 요소의 설정을 상세하게 Customize 할 수 있습니다.&lt;/p&gt;

&lt;p&gt;하지만, 이 문서에서는 Customize 없이 모든 구성 요소를 설치하기 위해 Demo Kubernetes 리소스를 사용하겠습니다.
이렇게 설치한 구성 요소는 Helm을 사용해 설치한 것과 동일합니다.&lt;/p&gt;

&lt;p&gt;이제 Istio를 설치해보겠습니다. 다운로드한 Istio root 디렉토리로 이동합니다.
Kubectl CLI를 사용해 &lt;code class=&quot;highlighter-rouge&quot;&gt;istio-demo.yaml&lt;/code&gt; 리소스를 Kubernetes Cluster에 배포합니다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ kubectl create -f install/kubernetes/istio-demo.yaml
namespace/istio-system created
customresourcedefinition.apiextensions.k8s.io/virtualservices.networking.istio.io created
...
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;배포가 완료되면 istio-system namespace에서 Istio 구성 요소를 조회할 수 있습니다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ kubectl get po -n istio-system
NAME                                      READY   STATUS      RESTARTS   AGE
grafana-97fb6966d-g6v9w                   1/1     Running     0          95m
istio-citadel-7c7c5f5c99-g5k4s            1/1     Running     0          95m
istio-cleanup-secrets-1.2.2-bcwf6         0/1     Completed   0          95m
istio-egressgateway-f7b8cc667-bj2kd       1/1     Running     0          95m
istio-galley-585fc86678-hb8vn             1/1     Running     0          95m
istio-grafana-post-install-1.2.2-ltg8f    0/1     Completed   0          95m
istio-ingressgateway-cfbf989b7-9zmmg      1/1     Running     0          95m
istio-pilot-68f587df5d-wzwxn              2/2     Running     0          95m
istio-policy-76cbcc4774-8clld             2/2     Running     2          95m
istio-security-post-install-1.2.2-glvhh   0/1     Completed   0          95m
istio-sidecar-injector-97f9878bc-54ssq    1/1     Running     0          95m
istio-telemetry-5f4575974c-gb9gt          2/2     Running     2          95m
istio-tracing-595796cf54-nqh82            1/1     Running     0          95m
kiali-55fcfc86cc-cvw4k                    1/1     Running     0          95m
prometheus-5679cb4dcd-nm4bv               1/1     Running     0          95m
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Istio는 data plane(service proxy)과 control plane으로 구성됩니다.&lt;/p&gt;

&lt;p&gt;Data plane은 application을 배포하지 않았기 때문에 아직 확인할 수 없습니다.
application을 배포하면 service proxy가 pod에 주입됩니다.&lt;/p&gt;

&lt;p&gt;Control plane은 아래와 같이 구성됩니다.
Grafana, Prometheus와 같이 익숙한 구성 요소도 있지만 익숙치 않은 구성 요소도 보입니다.
이 구성 요소에 대해서는 뒤에서 좀 더 살펴보도록 하겠습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/images/kubernetes/istio/istio-study-2.1-001.png&quot; alt=&quot;&quot; /&gt;
[출처: Istio in Action MEAP Edition]&lt;/p&gt;

&lt;p&gt;Istio control plane의 구성 요소가 단일 인스턴스로 배포되어 있는 것을 볼 수 있습니다.
이것을 보고 SPOF(Single Point Of Failure)라고 생각할 수 있습니다.
하지만 Istio는 HA(High Availability) 아키텍처를 고려하여 만들어졌습니다.
각 구성 요소는 다중 인스턴스로 배포할 수 있고, 일부 구성 요소에 오류가 있어도 일정 기간 지속될 수 있도록 탄력적으로 만들어져있습니다.&lt;/p&gt;

&lt;p&gt;이제 설치가 잘되었는지 정상적인 응답을 반환하는지 확인해보겠습니다.&lt;/p&gt;

&lt;p&gt;아래 명령을 실행하여 Istio의 설정을 조회해봅니다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ kubectl run -i --rm --restart=Never dummy --image=tutum/curl:alpine \
&amp;gt; -n istio-system --command \
&amp;gt; -- curl -v 'http://istio-pilot.istio-system:8080/v1/registration'
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;정상적인 응답이 온다면 아래와 같이 Istio 구성 요소의 endpoint를 확인할 수 있습니다.
이를 통해 우리는 Istio의 control plane에 mesh 설정과 enpoint를 질의할 수 있다는 것을 확인했습니다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;...
[
  {
   &quot;service-key&quot;: &quot;default-http-backend.kube-system.svc.cluster.local|http&quot;,
   &quot;hosts&quot;: [
    {
     &quot;ip_address&quot;: &quot;10.0.2.8&quot;,
     &quot;port&quot;: 8080
    }
   ]
  },
  {
   &quot;service-key&quot;: &quot;grafana.istio-system.svc.cluster.local|http&quot;,
   &quot;hosts&quot;: [
    {
     &quot;ip_address&quot;: &quot;10.0.0.8&quot;,
     &quot;port&quot;: 3000
    }
   ]
  },
  ...
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name>sj</name></author><category term="istio" /><category term="servicemesh" /><category term="kubernetes" /><summary type="html">이 문서에서는 Istio와 샘플 앱을 배포해보겠습니다.</summary></entry><entry><title type="html">Virtual Kubelet을 활용해 Kubernetes를 서버리스 컨테이너로 확장하기</title><link href="http://localhost:4000/blog/kubernetes/2019/08/25/virtual-kublet.html" rel="alternate" type="text/html" title="Virtual Kubelet을 활용해 Kubernetes를 서버리스 컨테이너로 확장하기" /><published>2019-08-25T00:00:00+09:00</published><updated>2019-08-25T00:00:00+09:00</updated><id>http://localhost:4000/blog/kubernetes/2019/08/25/virtual-kublet</id><content type="html" xml:base="http://localhost:4000/blog/kubernetes/2019/08/25/virtual-kublet.html">&lt;h2 id=&quot;overview&quot;&gt;Overview&lt;/h2&gt;
&lt;p&gt;Private 환경에서 kubernetes cluster를 운영하고 있다면 workload를 bursting 하는 관점에서 
Public cloud와 연계하는 방안을 한번쯤은 고민해봤을 것이라 생각합니다.&lt;/p&gt;

&lt;p&gt;이와 관련해 CNCF(Cloud Native Computing Foundation)에 
&lt;a href=&quot;https://github.com/virtual-kubelet/virtual-kubelet&quot;&gt;Virtual Kubelet&lt;/a&gt;이라는
흥미로운 프로젝트가 있어 활용 사례 및 Hands-on을 남겨봅니다.&lt;/p&gt;

&lt;p&gt;Virtual Kubelet에 대한 설명을 보면 &lt;code class=&quot;highlighter-rouge&quot;&gt;Kubernete를 다른 API와 연동하기 위한 Kubelet 구현체&lt;/code&gt;라고 정의되어 있습니다.
이 설명만 들으면 활용 방법이나 프로젝트에서 추구하는 목적이 크게 와닿지가 않습니다.&lt;/p&gt;

&lt;p&gt;이해를 돕기 위해 활용 사례를 들어보겠습니다.
아래 그림과 같이 운영중인 Kubernetes cluster에 Public Cloud의 서버리스 컨테이너 서비스
(예 - AWS ECS Fargate, Azure Container Instance 등)를 확장해 마치 하나의 cluster 처럼 사용할 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/images/kubernetes/virtual-kubelet/virtual-kubelet-architecture.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이를 통해 컨테이너 서비스 별로 서로 다른 사용 방식을 고려할 필요 없이 Kubernetes stack으로 통일하여 개발 및 운영을 할 수 있는 장점이 있습니다.
또한 Public cloud에는 Kubernetes cluster를 추가로 운영할 필요없이 컨테이너에 대한 비용만 지불하면 되므로 비용 효율적인 측면이 있습니다.&lt;/p&gt;

&lt;p&gt;물론 제약 사항도 있습니다. 아래 현재 지원하는 feature를 보면 kubernetes의 모든 기능을 사용할 수 있는 것은 아닙니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;create, delete and update pods&lt;/li&gt;
  &lt;li&gt;container logs, exec, and metrics&lt;/li&gt;
  &lt;li&gt;get pod, pods and pod status&lt;/li&gt;
  &lt;li&gt;capacity&lt;/li&gt;
  &lt;li&gt;node addresses, node capacity, node daemon endpoints&lt;/li&gt;
  &lt;li&gt;operating system&lt;/li&gt;
  &lt;li&gt;bring your own virtual network&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;또한 Virtual Kubelet에서 사용할 virtual network를 지정할 수 있지만 
해당 network가 Kubernetes cluster의 pod에서 사용하는 network과 연결성이 없다면 
pod간 private 통신도 불가능합니다.&lt;/p&gt;

&lt;p&gt;추가로 프로젝트 설명에 Multi Kubernetes cluster를 federation 하기 위한 용도가 아니라고 명시되어 있으니
사용에 참고가 필요할 거 같습니다.&lt;/p&gt;

&lt;p&gt;마지막으로 프로젝트 현황을 살펴보면 CNCF의 Sandbox 프로젝트라고 합니다.
일반적으로 Sandbox =&amp;gt; Incubation =&amp;gt; Graduate 순으로 발전된다고 합니다.&lt;/p&gt;

&lt;p&gt;최근 1.0 버전이 릴리스되어 프로젝트가 안정화되어 가는거 같고 
실용적인 활용 사례와 컨셉이 명확해 앞으로 기대가 되는 프로젝트입니다.&lt;/p&gt;

&lt;p&gt;아래 hands-on을 한번 따라해보시면 프로젝트 컨셉과 활용 방법에 대해 좀 더 쉽게 이해할 수 있으리라 생각됩니다.&lt;/p&gt;

&lt;h2 id=&quot;사전-준비하기&quot;&gt;사전 준비하기&lt;/h2&gt;

&lt;p&gt;이 문서에서는 누구나 따라할 수 있도록 Public cloud의 무료 체험이 가능한 환경 기준으로 작성했습니다.&lt;/p&gt;

&lt;p&gt;Kubernetes cluster는 GKE(Google Kubernetes Engine), 컨테이너 서비스는 ACI(Azure Container Instance)를 사용했습니다.&lt;/p&gt;

&lt;p&gt;Hands-on을 위해서 아래와 같은 준비사항이 필요합니다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Kubernetes cluster&lt;/p&gt;

    &lt;p&gt;기존의 보유하고 있는 cluster를 사용하거나 새로 생성합니다.&lt;/p&gt;

    &lt;p&gt;&lt;a href=&quot;https://cloud.google.com/kubernetes-engine/docs/quickstart?hl=ko&quot;&gt;GKE(Google Kubernetes Engine)&lt;/a&gt;,
 &lt;a href=&quot;https://azure.microsoft.com/ko-kr/services/kubernetes-service/&quot;&gt;AKS(Azure Kubernetes Service)&lt;/a&gt;, 
 &lt;a href=&quot;https://aws.amazon.com/ko/eks/&quot;&gt;EKS(Elastic Kubernetes Service)&lt;/a&gt; 
 등 관리형 Kubernetes 서비스를 활용하여 쉽고 빠르게 생성할 수 있습니다.&lt;/p&gt;

    &lt;p&gt;이 문서에서는 GKE 환경을 사용했습니다. 구글 계정을 가지고 있다면 Credit을 받아 일정기간 무료로 사용할 수 있습니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Azure 계정&lt;/p&gt;

    &lt;p&gt;ACI(Azure Container Instance)를 사용하기 위해 Azure 계정을 준비합니다.&lt;/p&gt;

    &lt;p&gt;Azure 계정이 없다면 &lt;a href=&quot;https://azure.microsoft.com/ko-kr/free/&quot;&gt;Azure 체험 계정 만들기&lt;/a&gt;를 통하여 
 계정을 생성하고 Credit을 받아 일정기간 무료로 사용할 수 있습니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Azure CLI.&lt;/p&gt;

    &lt;p&gt;Azure CLI를 설치합니다.&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;OSX&lt;/p&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  brew install azure-cli
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Linux(Ubuntu 64-bit)&lt;/p&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  $ echo &quot;deb [arch=amd64] https://packages.microsoft.com/repos/azure-cli/ wheezy main&quot; | \
  sudo tee /etc/apt/sources.list.d/azure-cli.list
 
  $ sudo apt-key adv --keyserver packages.microsoft.com --recv-keys 52E16F86FEE04B979B07E28DB02C46DF417A0893
  $ sudo apt-get install apt-transport-https
  $ sudo apt-get update &amp;amp;&amp;amp; sudo apt-get install azure-cli
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Kubernetes CLI&lt;/p&gt;

    &lt;p&gt;&lt;a href=&quot;https://kubernetes.io/docs/tasks/tools/install-kubectl/&quot;&gt;Kubernetes CLI&lt;/a&gt;를 설치합니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Helm CLI.&lt;/p&gt;

    &lt;p&gt;&lt;a href=&quot;/blog/helm/2018/05/27/installing-helm.html&quot;&gt;Helm CLI&lt;/a&gt;를 설치합니다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;azure-계정-설정하기&quot;&gt;Azure 계정 설정하기&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Azure에 로그인합니다.&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; az login
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Azure subscription 조회 및 복사합니다.&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ az account list -o table
 Name       CloudName    SubscriptionId                        State    IsDefault
 ---------  -----------  ------------------------------------  -------  -----------
 무료 체험    AzureCloud   &amp;lt;SubscriptionId&amp;gt;                      Enabled  True
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Subscription ID에 위에서 복사한 ID를 저장합니다.&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; export AZURE_SUBSCRIPTION_ID=&quot;&amp;lt;SubscriptionId&amp;gt;&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;ACI(Azure Container Instance)를 활성화합니다.&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; az provider register -n Microsoft.ContainerInstance
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;aci-resource-group-생성하기&quot;&gt;ACI Resource Group 생성하기&lt;/h2&gt;

&lt;p class=&quot;tip-title&quot;&gt;참고&lt;/p&gt;
&lt;p class=&quot;tip-content&quot;&gt;
현재 Azure 한국 리전에서는 ACI 서비스가 없습니다. 
서비스 중인 가장 가까운 리전은 japaneast 입니다.(japanwest도 없음)
&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;export ACI_REGION=japaneast
az group create --name aci-group --location &quot;$ACI_REGION&quot;
export AZURE_RG=aci-group
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;azure-service-principal-생성하기&quot;&gt;Azure Service principal 생성하기&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;RBAC과 함께 SP(Service principal)를 생성합니다.&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ az ad sp create-for-rbac --name virtual-kubelet-quickstart -o table
 ...
 AppId       DisplayName        Name                Password                  Tenant
 -----------------------------------------------------------------------------------------------  
 &amp;lt;AppId&amp;gt;     ...                ...                 &amp;lt;Password&amp;gt;                &amp;lt;Tenant&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;위의 결과를 변수로 저장합니다.&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; export AZURE_TENANT_ID=&amp;lt;Tenant&amp;gt;
 export AZURE_CLIENT_ID=&amp;lt;AppId&amp;gt;
 export AZURE_CLIENT_SECRET=&amp;lt;Password&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;virtual-kubelet-배포하기&quot;&gt;Virtual Kubelet 배포하기&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Cluster의 Master Endpoint 확인 및 복사합니다.&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ kubectl cluster-info
 Kubernetes master is running at &amp;lt;Kubernetes Master&amp;gt;
 ...

 $ export MASTER_URI=&amp;lt;Kubernetes Master&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Helm을 통하여 Virtual Kubelet 설치합니다.&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; VK_RELEASE=virtual-kubelet-latest
 RELEASE_NAME=virtual-kubelet
 NODE_NAME=virtual-kubelet
 CHART_URL=https://github.com/virtual-kubelet/virtual-kubelet/raw/master/charts/$VK_RELEASE.tgz

 helm install &quot;$CHART_URL&quot; --name &quot;$RELEASE_NAME&quot; \
 --set provider=azure \
 --set rbac.install=true \
 --set providers.azure.targetAKS=false \
 --set providers.azure.aciResourceGroup=$AZURE_RG \
 --set providers.azure.aciRegion=$ACI_REGION \
 --set providers.azure.tenantId=$AZURE_TENANT_ID \
 --set providers.azure.subscriptionId=$AZURE_SUBSCRIPTION_ID \
 --set providers.azure.clientId=$AZURE_CLIENT_ID \
 --set providers.azure.clientKey=$AZURE_CLIENT_SECRET \
 --set providers.azure.masterUri=$MASTER_URI
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;정상 설치 확인하기&lt;/p&gt;

    &lt;p&gt;virtual-kubelet이 cluster에 Pod로 배포되었고, Running 중인지 확인합니다.&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ kubectl --namespace=default get pods -l &quot;app=virtual-kubelet&quot;
 NAME                                               READY   STATUS    RESTARTS   AGE
 virtual-kubelet-virtual-kubelet-7c9fbc55c4-r2j57   1/1     Running   0          23s
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;p&gt;Cluster의 node를 조회해 virtual-kubelet node가 조회되는지 확인합니다.&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ kubectl get nodes
 NAME                                                STATUS   ROLES    AGE   VERSION
 gke-standard-cluster-1-default-pool-cc858c9e-9sf8   Ready    &amp;lt;none&amp;gt;   39m   v1.12.8-gke.10
 gke-standard-cluster-1-default-pool-cc858c9e-bm01   Ready    &amp;lt;none&amp;gt;   39m   v1.12.8-gke.10
 virtual-kubelet                                     Ready    agent    44s   v1.13.1-vk-v0.9.0-1-g7b92d1ee-dev
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;sample-app-배포하기&quot;&gt;Sample App 배포하기&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;virtual-node.yaml 파일을 생성합니다.
ACI(Azure Container Instance)에 배포하기 위해 nodeSelector와 toleration을 추가합니다.&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;apiVersion: apps/v1
kind: Deployment
metadata:
  name: aci-helloworld
spec:
  replicas: 1
  selector:
 matchLabels:
   app: aci-helloworld
  template:
 metadata:
   labels:
     app: aci-helloworld
 spec:
   containers:
   - name: aci-helloworld
     image: microsoft/aci-helloworld
     ports:
     - containerPort: 80
   nodeSelector:
     kubernetes.io/role: agent
     beta.kubernetes.io/os: linux
     type: virtual-kubelet
   tolerations:
   - key: virtual-kubelet.io/provider
     operator: Exists
   - key: azure.com/aci
     effect: NoSchedule
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;aci-helloworld pod를 배포합니다.&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ kubectl apply -f virtual-node.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;배포 후 Pod를 조회해보면 aci-helloworld app은 virtual-kubelt node에 배포된 것을 확인할 수 있습니다.&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ kubectl get po -o wide
 NAME                 READY STATUS    RESTARTS   AGE    IP              NODE              NOMINATED NODE
 aci-helloworld-...   1/1   Running   0          54s    [IP_ADDRESS]    virtual-kubelet   &amp;lt;none&amp;gt;
 sample-app-...       1/1   Running   0          4m17s  10.0.0.7        gke-standard...   &amp;lt;none&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;p&gt;aci-helloworld pod의 IP를 보면 azure의 public ip를 할당받은것을 확인할 수 있습니다.
 Virtual Kubelet 배포 시 별도의 vitual network 설정을 하지 않았기 때문입니다.&lt;/p&gt;

    &lt;p&gt;aci-helloworld pod의 [IP_ADDRESS]를 정보를 복사한 후 웹브라우저에서 접속하면 
 &lt;code class=&quot;highlighter-rouge&quot;&gt;Welcome to Azure Container Instances!&lt;/code&gt; 메세지를 확인할 수 있습니다.&lt;/p&gt;

    &lt;p&gt;마지막으로 Azure Port에 접속해 ACI resource group에서 aci-helloworld 앱이 배포된것을 확인할 수 있습니다.&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;/blog/assets/images/kubernetes/virtual-kubelet/virtual-kubelet-aci.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;</content><author><name>sj</name></author><category term="kubernetes" /><category term="virtualkubelet" /><category term="cloud" /><category term="container" /><summary type="html">Overview Private 환경에서 kubernetes cluster를 운영하고 있다면 workload를 bursting 하는 관점에서 Public cloud와 연계하는 방안을 한번쯤은 고민해봤을 것이라 생각합니다.</summary></entry><entry><title type="html">Istio를 활용해 Multi Cluster 환경에 Service Mesh 구성하기</title><link href="http://localhost:4000/blog/istio/2019/08/11/istio-multi-cluster-mesh.html" rel="alternate" type="text/html" title="Istio를 활용해 Multi Cluster 환경에 Service Mesh 구성하기" /><published>2019-08-11T00:00:00+09:00</published><updated>2019-08-11T00:00:00+09:00</updated><id>http://localhost:4000/blog/istio/2019/08/11/istio-multi-cluster-mesh</id><content type="html" xml:base="http://localhost:4000/blog/istio/2019/08/11/istio-multi-cluster-mesh.html">&lt;h2 id=&quot;overview&quot;&gt;Overview&lt;/h2&gt;

&lt;p&gt;Istio를 활용하여 여러개의 Kubernetes Cluster 환경에 Service Mesh를 구성할 수 있습니다.&lt;/p&gt;

&lt;p&gt;인프라 및 Kubernetes Cluster 환경에 따라 3가지 구성 방법이 있습니다.&lt;/p&gt;

&lt;p&gt;이 문서에서는 1번 방법을 활용하여 Service Mesh를 구성해보겠습니다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://istio.io/docs/setup/kubernetes/install/multicluster/shared-gateways/&quot;&gt;Shared control plane (multi-network)&lt;/a&gt;&lt;/p&gt;

    &lt;p&gt;이 방법은 여러개의 Cluster가 하나의 Istio Control Plane을 공유합니다.
 Istio Gateway를 통해 Cluster간 통신하므로 각 Cluster의 네트워크가 분리되어 있고 VPN 또는 Direct 네트워크로 연결되어 있지 않아도 됩니다.&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;/blog/assets/images/kubernetes/istio/istio-shared-multi.svg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://istio.io/docs/setup/kubernetes/install/multicluster/shared-vpn/&quot;&gt;Shared control plane (single-network)&lt;/a&gt;&lt;/p&gt;

    &lt;p&gt;1번과 마찬가지로 여러개의 Cluster가 하나의 Istio Control Plane을 공유합니다.
 별도의 Gateway가 없기 때문에 각 Cluster의 네트워크가 VPN 등을 통해 연결성이 있어야합니다.
 각 Cluster의 네트워크에서 Pod와 Service의 CIDR은 중복되서는 안되고 서로간의 라우팅이 가능해야합니다.&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;/blog/assets/images/kubernetes/istio/istio-shared-single.svg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://istio.io/docs/setup/kubernetes/install/multicluster/gateways/&quot;&gt;Multiple control planes&lt;/a&gt;&lt;/p&gt;

    &lt;p&gt;1번과 마찬가지로 Istio Gateway를 통해 Cluster간 통신을 하지만 Istio Control Plance을 공유하지 않고 각각의 Cluster에 설치합니다.&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;/blog/assets/images/kubernetes/istio/istio-multiple-multi.svg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;준비하기&quot;&gt;준비하기&lt;/h2&gt;

&lt;h3 id=&quot;kubernetes-cluster-준비&quot;&gt;Kubernetes Cluster 준비&lt;/h3&gt;

&lt;p&gt;1.12, 1.13, 1.14 버전의 Kubernetes Cluster를 2개 이상 준비합니다.
이 문서에서는 1.12 버전의 2개의 Cluster를 활용하겠습니다.&lt;/p&gt;

&lt;p&gt;편의상 2개의 Cluster를 아래와 같이 환경 변수로 설정합니다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ kubectl config get-contexts
CURRENT   NAME       CLUSTER    AUTHINFO       NAMESPACE
*         cluster1   cluster1   user@foo.com   default
          cluster2   cluster2   user@foo.com   default

$ export CTX_CLUSTER1=$(kubectl config view -o jsonpath='{.contexts[0].name}')
$ export CTX_CLUSTER2=$(kubectl config view -o jsonpath='{.contexts[1].name}')
$ echo CTX_CLUSTER1 = ${CTX_CLUSTER1}, CTX_CLUSTER2 = ${CTX_CLUSTER2}
CTX_CLUSTER1 = cluster1, CTX_CLUSTER2 = cluster2
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;istio-다운로드&quot;&gt;Istio 다운로드&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/istio/istio/releases&quot;&gt;Istio Release&lt;/a&gt; 페이지에서 원하는 버전을 다운로드합니다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;curl -L https://git.io/getLatestIstio | ISTIO_VERSION=x.x.x sh -
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;platform-설정&quot;&gt;Platform 설정&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://istio.io/docs/setup/kubernetes/platform-setup/&quot;&gt;platform-specific setup&lt;/a&gt; 페이지를 참고하여 각 클라우드별로
필요한 설정을합니다.&lt;/p&gt;

&lt;h3 id=&quot;helm-설치&quot;&gt;Helm 설치&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;/blog/helm/2018/05/27/installing-helm.html&quot;&gt;Helm 설치하기&lt;/a&gt; 문서를 참고하여 Helm Client를 설치합니다.&lt;/p&gt;

&lt;h2 id=&quot;multi-cluster에-service-mesh-구성하기&quot;&gt;Multi Cluster에 Service Mesh 구성하기&lt;/h2&gt;

&lt;h3 id=&quot;primary-cluster-설정&quot;&gt;Primary Cluster 설정&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Primary Cluster의 Istio deployment yaml 생성합니다.&lt;/p&gt;

    &lt;p&gt;위에서 다운로드 받은 Istio 디렉토리로 이동합니다.&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ cd istio-x.x.x
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;p&gt;helm template 기능을 사용하여 istio deployment yaml 파일을 생성합니다.&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ helm template --name=istio --namespace=istio-system \
 --set global.mtls.enabled=true \
 --set security.selfSigned=false \
 --set global.controlPlaneSecurityEnabled=true \
 --set global.proxy.accessLogFile=&quot;/dev/stdout&quot; \
 --set global.meshExpansion.enabled=true \
 --set 'global.meshNetworks.network1.endpoints[0].fromRegistry'=Kubernetes \
 --set 'global.meshNetworks.network1.gateways[0].address'=0.0.0.0 \
 --set 'global.meshNetworks.network1.gateways[0].port'=443 \
 --set gateways.istio-ingressgateway.env.ISTIO_META_NETWORK=&quot;network1&quot; \
 --set global.network=&quot;network1&quot; \
 --set 'global.meshNetworks.network2.endpoints[0].fromRegistry'=n2-k8s-config \
 --set 'global.meshNetworks.network2.gateways[0].address'=0.0.0.0 \
 --set 'global.meshNetworks.network2.gateways[0].port'=443 \
 install/kubernetes/helm/istio &amp;gt; istio-auth.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Primary Cluster에 Istio를 설치합니다.&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ kubectl create --context=$CTX_CLUSTER1 ns istio-system
 $ kubectl create --context=$CTX_CLUSTER1 secret generic cacerts -n istio-system --from-file=samples/certs/ca-cert.pem --from-file=samples/certs/ca-key.pem --from-file=samples/certs/root-cert.pem --from-file=samples/certs/cert-chain.pem
 $ for i in install/kubernetes/helm/istio-init/files/crd*yaml; do kubectl apply --context=$CTX_CLUSTER1 -f $i; done
 $ kubectl apply --context=$CTX_CLUSTER1 -f istio-auth.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;p&gt;아래와 같이 모든 Pod의 Running 상태가 될 때까지 기다립니다.&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ kubectl get pods --context=$CTX_CLUSTER1 -n istio-system
 NAME                                      READY   STATUS      RESTARTS   AGE
 istio-citadel-9bbf9b4c8-nnmbt             1/1     Running     0          2m8s
 istio-cleanup-secrets-1.1.0-x9crw         0/1     Completed   0          2m12s
 istio-galley-868c5fff5d-9ph6l             1/1     Running     0          2m9s
 istio-ingressgateway-6c756547b-dwc78      1/1     Running     0          2m8s
 istio-pilot-54fcf8db8-sn9cn               2/2     Running     0          2m8s
 istio-policy-5fcbd55d8b-xhbpz             2/2     Running     2          2m8s
 istio-security-post-install-1.1.0-ww5zz   0/1     Completed   0          2m12s
 istio-sidecar-injector-6dcc9d5c64-7hnnl   1/1     Running     0          2m8s
 istio-telemetry-57875ffb6d-n2vmf          2/2     Running     3          2m8s
 prometheus-66c9f5694-8pccr                1/1     Running     0          2m8s
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Ingress Gateway를 생성합니다.&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ kubectl apply --context=$CTX_CLUSTER1 -f - &amp;lt;&amp;lt;EOF
 apiVersion: networking.istio.io/v1alpha3
 kind: Gateway
 metadata:
 name: cluster-aware-gateway
 namespace: istio-system
 spec:
 selector:
     istio: ingressgateway
 servers:
 - port:
     number: 443
     name: tls
     protocol: TLS
     tls:
     mode: AUTO_PASSTHROUGH
     hosts:
     - &quot;*.local&quot;
 EOF
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Primary Cluster의 Ingress IP와 Port를 확인합니다.&lt;/p&gt;

    &lt;p&gt;Primary Cluster에서 Ingress Gateway의 Service를 조회합니다.&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ kubectl config use-context $CTX_CLUSTER1
 $ kubectl get svc istio-ingressgateway -n istio-system
 NAME                   TYPE           CLUSTER-IP       EXTERNAL-IP     PORT(S)                                      AGE
 istio-ingressgateway   LoadBalancer   172.x.x.1        130.x.x.1       80:31380/TCP,443:31390/TCP,31400:31400/TCP   17h
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;p&gt;Ingress의 Host 주소와 Secure port를 확인합니다.&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ export INGRESS_HOST=$(kubectl -n istio-system get service istio-ingressgateway -o jsonpath='{.status.loadBalancer.ingress[0].ip}')
 $ export SECURE_INGRESS_PORT=$(kubectl -n istio-system get service istio-ingressgateway -o jsonpath='{.spec.ports[?(@.name==&quot;https&quot;)].port}')
 $ echo The ingress gateway of cluster1: address=$INGRESS_HOST, port=$SECURE_INGRESS_PORT
 130.x.x.1, 443
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Istio Configmap의 mesh nework 설정에서 gateway 주소를 위에서 조회한 Ingress 정보로 변경합니다.&lt;/p&gt;

    &lt;p&gt;data.mesh.meshNetworks.networks.network1.address를 0.0.0.0에서 INGRESS_HOST로 변경합니다.
 data.mesh.meshNetworks.networks.network1.port를 443에서 SECURE_INGRESS_PORT 변경합니다.&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ kubectl edit cm -n istio-system --context=$CTX_CLUSTER1 istio
 apiVersion: v1
 data:
     mesh:
     ...
         meshNetworks: &quot;networks:\n  network1:\n    endpoints:\n    - fromRegistry: Kubernetes\n
     \   gateways:\n    - address: 0.0.0.0\n      port: 443\n  ...
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;second-cluster-설정&quot;&gt;Second Cluster 설정&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Primary Cluster의 Ingress Gateway 주소를 확인합니다.&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ export LOCAL_GW_ADDR=$(kubectl get --context=$CTX_CLUSTER1 svc --selector=app=istio-ingressgateway \
 -n istio-system -o jsonpath='{.items[0].status.loadBalancer.ingress[0].ip}') &amp;amp;&amp;amp; echo ${LOCAL_GW_ADDR}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Second Cluster의 Istio deployment yaml 생성합니다.&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ helm template --name istio-remote --namespace=istio-system \
 --values install/kubernetes/helm/istio/values-istio-remote.yaml \
 --set global.mtls.enabled=true \
 --set gateways.enabled=true \
 --set security.selfSigned=false \
 --set global.controlPlaneSecurityEnabled=true \
 --set global.createRemoteSvcEndpoints=true \
 --set global.remotePilotCreateSvcEndpoint=true \
 --set global.remotePilotAddress=${LOCAL_GW_ADDR} \
 --set global.remotePolicyAddress=${LOCAL_GW_ADDR} \
 --set global.remoteTelemetryAddress=${LOCAL_GW_ADDR} \
 --set gateways.istio-ingressgateway.env.ISTIO_META_NETWORK=&quot;network2&quot; \
 --set global.network=&quot;network2&quot; \
 install/kubernetes/helm/istio &amp;gt; istio-remote-auth.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Second Cluster에 Istio를 설치합니다.&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ kubectl create --context=$CTX_CLUSTER2 ns istio-system
 $ kubectl create --context=$CTX_CLUSTER2 secret generic cacerts -n istio-system --from-file=samples/certs/ca-cert.pem --from-file=samples/certs/ca-key.pem --from-file=samples/certs/root-cert.pem --from-file=samples/certs/cert-chain.pem
 $ kubectl apply --context=$CTX_CLUSTER2 -f istio-remote-auth.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;p&gt;Istio의 모든 Pod가 Running 상태가 될때까지 기다립니다. 
 Primary Cluster와 다르게 일부 컴포넌트만 설치됩니다.&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ kubectl get pods --context=$CTX_CLUSTER2 -n istio-system -l istio!=ingressgateway
 NAME                                     READY   STATUS      RESTARTS   AGE
 istio-citadel-75c8fcbfcf-9njn6           1/1     Running     0          12s
 istio-cleanup-secrets-1.1.0-vtp62        0/1     Completed   0          14s
 istio-sidecar-injector-cdb5d4dd5-rhks9   1/1     Running     0          12s
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Second Cluster의 Ingress IP와 Port를 확인합니다.&lt;/p&gt;

    &lt;p&gt;Second Cluster에서 Ingress Gateway의 Service를 조회합니다.&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ kubectl config use-context $CTX_CLUSTER2
 $ kubectl get svc istio-ingressgateway -n istio-system
 NAME                   TYPE           CLUSTER-IP       EXTERNAL-IP     PORT(S)                                      AGE
 istio-ingressgateway   LoadBalancer   172.x.x.2        130.x.x.2       80:31380/TCP,443:31390/TCP,31400:31400/TCP   17h
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;p&gt;Ingress의 Host 주소와 Secure port를 확인합니다.&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ export INGRESS_HOST=$(kubectl -n istio-system get service istio-ingressgateway -o jsonpath='{.status.loadBalancer.ingress[0].ip}')
 $ export SECURE_INGRESS_PORT=$(kubectl -n istio-system get service istio-ingressgateway -o jsonpath='{.spec.ports[?(@.name==&quot;https&quot;)].port}')
 $ echo The ingress gateway of cluster2: address=$INGRESS_HOST, port=$SECURE_INGRESS_PORT
 130.x.x.2, 443
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Istio Configmap의 mesh nework 설정에서 gateway 주소를 위에서 조회한 Ingress 정보로 변경합니다.&lt;/p&gt;

    &lt;p&gt;data.mesh.meshNetworks.networks.network2.address를 0.0.0.0에서 INGRESS_HOST로 변경합니다.
 data.mesh.meshNetworks.networks.network2.port를 443에서 SECURE_INGRESS_PORT 변경합니다.&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ kubectl edit cm -n istio-system --context=$CTX_CLUSTER2 istio
 apiVersion: v1
 data:
     mesh:
     ...
     meshNetworks: &quot;networks:\n  network1:\n    endpoints:\n    - fromRegistry: Kubernetes\n
         \   gateways:\n    - address: 0.0.0.0\n      port: 443\n  network2:\n    endpoints:\n
         \   - fromRegistry: n2-k8s-config\n    gateways:\n    - address: 0.0.0.0\n
         \     port: 443\n  &quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;n2-k8s-config 설정 파일을 생성하기 위한 환경 변수를 설정합니다.&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ CLUSTER_NAME=$(kubectl --context=$CTX_CLUSTER2 config view --minify=true -o jsonpath='{.clusters[].name}')
 $ SERVER=$(kubectl --context=$CTX_CLUSTER2 config view --minify=true -o jsonpath='{.clusters[].cluster.server}')
 $ SECRET_NAME=$(kubectl --context=$CTX_CLUSTER2 get sa istio-multi -n istio-system -o jsonpath='{.secrets[].name}')
 $ CA_DATA=$(kubectl get --context=$CTX_CLUSTER2 secret ${SECRET_NAME} -n istio-system -o jsonpath=&quot;{.data['ca\.crt']}&quot;)
 $ TOKEN=$(kubectl get --context=$CTX_CLUSTER2 secret ${SECRET_NAME} -n istio-system -o jsonpath=&quot;{.data['token']}&quot; | base64 --decode)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;n2-k8s-config 파일을 생성합니다.&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ cat &amp;lt;&amp;lt;EOF &amp;gt; n2-k8s-config
 apiVersion: v1
 kind: Config
 clusters:
 - cluster:
     certificate-authority-data: ${CA_DATA}
     server: ${SERVER}
     name: ${CLUSTER_NAME}
 contexts:
 - context:
     cluster: ${CLUSTER_NAME}
     user: ${CLUSTER_NAME}
     name: ${CLUSTER_NAME}
 current-context: ${CLUSTER_NAME}
 users:
 - name: ${CLUSTER_NAME}
     user:
     token: ${TOKEN}
 EOF
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;primary-cluster와-second-cluster-동기화&quot;&gt;Primary Cluster와 Second Cluster 동기화&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Primary Cluster에서 Second Cluster를 동기화합니다.&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ kubectl create --context=$CTX_CLUSTER1 secret generic n2-k8s-secret --from-file n2-k8s-config -n istio-system
 $ kubectl label --context=$CTX_CLUSTER1 secret n2-k8s-secret istio/multiCluster=true -n istio-system
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Second Cluster의 Ingress Gateway가 Running 상태가 될때까지 기다립니다.&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ kubectl get pods --context=$CTX_CLUSTER2 -n istio-system -l istio=ingressgateway
 NAME                                    READY     STATUS    RESTARTS   AGE
 istio-ingressgateway-5c667f4f84-bscff   1/1       Running   0          16m
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;이제 Primary Cluster와 Seconde Cluster가 Service Mesh로 구성되었습니다.&lt;/p&gt;

&lt;p&gt;다음으로 샘플 서비스를 배포하여 2개의 Cluster에서 Service Mesh가 어떻게 동작하는지 확인해보겠습니다.&lt;/p&gt;

&lt;h2 id=&quot;샘플-서비스-배포하기&quot;&gt;샘플 서비스 배포하기&lt;/h2&gt;

&lt;p&gt;Overview의 구성도와 같이 helloworld 애플리케이션을 Primary와 Second 클러스터에 각각 배포할것입니다.&lt;/p&gt;

&lt;p&gt;각각의 인스턴스는 동일한 애플리케이션이지만 이미지의 버전이 v1, v2로 다릅니다.&lt;/p&gt;

&lt;h3 id=&quot;second-cluster에-helloworld-v2-버전-배포&quot;&gt;Second Cluster에 helloworld v2 버전 배포&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;sample namespace를 생성하고 istio proxy가 자동으로 injection 되도록 설정합니다.&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ kubectl create --context=$CTX_CLUSTER2 ns sample
 $ kubectl label --context=$CTX_CLUSTER2 namespace sample istio-injection=enabled
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;helloworld v2를 배포합니다.&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ kubectl create --context=$CTX_CLUSTER2 -f samples/helloworld/helloworld.yaml -l app=helloworld -n sample
 $ kubectl create --context=$CTX_CLUSTER2 -f samples/helloworld/helloworld.yaml -l version=v2 -n sample
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;helloworld v2가 Running 상태가 될때까지 기다립니다.&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ kubectl get po --context=$CTX_CLUSTER2 -n sample
 NAME                             READY     STATUS    RESTARTS   AGE
 helloworld-v2-7dd57c44c4-f56gq   2/2       Running   0          35s
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;primary-cluster에-helloworld-v1-버전-배포&quot;&gt;Primary Cluster에 helloworld v1 버전 배포&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;sample namespace를 생성하고 istio proxy가 자동으로 injection 되도록 설정합니다.&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ kubectl create --context=$CTX_CLUSTER1 ns sample
 $ kubectl label --context=$CTX_CLUSTER1 namespace sample istio-injection=enabled
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;helloworld v1을 배포합니다.&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ kubectl create --context=$CTX_CLUSTER1 -f samples/helloworld/helloworld.yaml -l app=helloworld -n sample
 $ kubectl create --context=$CTX_CLUSTER1 -f samples/helloworld/helloworld.yaml -l version=v1 -n sample
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;helloworld v1이 Running 상태가 될때까지 기다립니다.&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ kubectl get po --context=$CTX_CLUSTER1 -n sample
 NAME                            READY     STATUS    RESTARTS   AGE
 helloworld-v1-d4557d97b-pv2hr   2/2       Running   0          40s
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;cluster간-트래픽-흐름-확인&quot;&gt;Cluster간 트래픽 흐름 확인&lt;/h3&gt;

&lt;p&gt;2개의 Cluster에서 트래픽을 확인하기 위해 sleep 애플리케이션에서 helloworld 애플리케이션을 호출해보겠습니다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;sleep 애플리케이션을 2개의 Cluster에 배포하고 Running 상태가 될때까지 기다립니다.&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ kubectl apply --context=$CTX_CLUSTER1 -f samples/sleep/sleep.yaml -n sample
 $ kubectl apply --context=$CTX_CLUSTER2 -f samples/sleep/sleep.yaml -n sample
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Primary Cluster에서 helloworld를 여러번 호출합니다.&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; kubectl exec --context=$CTX_CLUSTER1 -it -n sample -c sleep $(kubectl get pod --context=$CTX_CLUSTER1 -n sample -l app=sleep -o jsonpath='{.items[0].metadata.name}') -- curl helloworld.sample:5000/hello
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;p&gt;각 클러스터의 v1, v2 버전이 번갈아가면서 호출되는 것을 확인할 수 있습니다.&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; Hello version: v2, instance: helloworld-v2-758dd55874-6x4t8
 Hello version: v1, instance: helloworld-v1-86f77cd7bd-cpxhv
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;p&gt;Primary Cluster의 sleep pod의 istio-proxy 컨테이너의 로그를 조회해봅니다.
 한번은 Second Cluster의 Gateway를 통하여 Second Cluster에 있는 helloworld v2가 호출되었고
 다른 한번은 같은 Cluster의 helloworld v1이 호출되었습니다.&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ kubectl logs --context=$CTX_CLUSTER1 -n sample $(kubectl get pod --context=$CTX_CLUSTER1 -n sample -l app=sleep -o jsonpath='{.items[0].metadata.name}') istio-proxy
 [2018-11-25T12:37:52.077Z] &quot;GET /hello HTTP/1.1&quot; 200 - 0 60 190 189 &quot;-&quot; &quot;curl/7.60.0&quot; &quot;6e096efe-f550-4dfa-8c8c-ba164baf4679&quot; &quot;helloworld.sample:5000&quot; &quot;130.x.x.2:15443&quot; outbound|5000||helloworld.sample.svc.cluster.local - 10.20.194.146:5000 10.10.0.89:59496 -
 [2018-11-25T12:38:06.745Z] &quot;GET /hello HTTP/1.1&quot; 200 - 0 60 171 170 &quot;-&quot; &quot;curl/7.60.0&quot; &quot;6f93c9cc-d32a-4878-b56a-086a740045d2&quot; &quot;helloworld.sample:5000&quot; &quot;10.10.0.90:5000&quot; outbound|5000||helloworld.sample.svc.cluster.local - 10.20.194.146:5000 10.10.0.89:59646 -
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;지금까지 살펴본 내용을 보면 Istio의 Service Mesh 구성을 통해 서로 다른 네트워크에 구성한 Cluster에서 실행중인 서비스간의 통신이
가능하다는 것을 확인할 수 있었습니다.&lt;/p&gt;</content><author><name>sj</name></author><category term="istio" /><category term="servicemesh" /><category term="multicluster" /><category term="kubernetes" /><summary type="html">Overview</summary></entry><entry><title type="html">Jenkins CI를 활용한 지속적인 소스코드 통합 환경 구성하기</title><link href="http://localhost:4000/blog/cicd/2019/08/04/jenkinsci.html" rel="alternate" type="text/html" title="Jenkins CI를 활용한 지속적인 소스코드 통합 환경 구성하기" /><published>2019-08-04T00:00:00+09:00</published><updated>2019-08-04T00:00:00+09:00</updated><id>http://localhost:4000/blog/cicd/2019/08/04/jenkinsci</id><content type="html" xml:base="http://localhost:4000/blog/cicd/2019/08/04/jenkinsci.html">&lt;h2 id=&quot;overview&quot;&gt;Overview&lt;/h2&gt;

&lt;p&gt;소스코드를 지속적으로 통합하기 위해서 TravisCI, CircleCI, Jenkins 등 다양한 툴을 활용할 수 있습니다.&lt;/p&gt;

&lt;p&gt;이 문서에서는 Jenkins CI를 활용하여 소스코드를 지속적으로 통합하는 방법을 알아보겠습니다.&lt;/p&gt;

&lt;p&gt;Jenkins CI와 아래 서비스를 통합하여 CI 환경을 구성해보겠습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;소스코드 저장소: Github&lt;/li&gt;
  &lt;li&gt;이미지 저장소: Docker Hub&lt;/li&gt;
  &lt;li&gt;통합(CI): Jenkins&lt;/li&gt;
  &lt;li&gt;애플리케이션 서버: Kubernetes&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;사전-준비&quot;&gt;사전 준비&lt;/h2&gt;

&lt;h3 id=&quot;소스코드-다운로드&quot;&gt;소스코드 다운로드&lt;/h3&gt;

&lt;p&gt;이 문서에서 사용할 &lt;a href=&quot;https://github.com/YunSangJun/jenkinsci-demo.git&quot;&gt;jenkinsci-demo&lt;/a&gt; 프로젝트를 복사합니다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git clone https://github.com/YunSangJun/jenkinsci-demo.git
cd jenkinsci-demo
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;소스코드-저장소&quot;&gt;소스코드 저장소&lt;/h3&gt;

&lt;p&gt;Github에 sample-app 저장소를 생성합니다.&lt;/p&gt;

&lt;h3 id=&quot;이미지-저장소-준비&quot;&gt;이미지 저장소 준비&lt;/h3&gt;

&lt;p&gt;Docker Hub에 sample-app 저장소를 생성합니다.&lt;/p&gt;

&lt;h3 id=&quot;kubernetes-클러스터-구성&quot;&gt;Kubernetes 클러스터 구성&lt;/h3&gt;

&lt;p&gt;애플리케이션 서버로 사용할 Kubernetes 클러스터를 준비합니다.&lt;/p&gt;

&lt;h3 id=&quot;jenkins-설치&quot;&gt;Jenkins 설치&lt;/h3&gt;

&lt;p&gt;Jenkins를 설치할 namespace를 생성합니다.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubectl create namespace jenkins
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;위에서 다운로드한 jenkinsci-demo 디렉토리로 이동합니다.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cd jenkinsci-demo
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Jenkins Helm chart를 설치합니다.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;helm install --name jenkins-release --namespace jenkins \
-f jenkins/values.yaml stable/jenkins
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Maven Build Cache 용도의 pvc를 생성합니다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubectl create -f jenkins/maven-cache-pvc.yaml -n jenkins
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Jenkins에 대한 자세한 내용은 &lt;a href=&quot;/blog/cicd/2018/05/26/installing-jenkins.html&quot;&gt;Jenkins 설치하기&lt;/a&gt; 문서를 참고하세요.&lt;/p&gt;

&lt;h2 id=&quot;jenkins-ui-접속&quot;&gt;Jenkins UI 접속&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Jenkins UI에 접속하기 위해 포트포워딩을 설정합니다.&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; export POD_NAME=$(kubectl get pods --namespace jenkins -l &quot;app.kubernetes.io/component=jenkins-master&quot; -l &quot;app.kubernetes.io/instance=jenkins-release&quot; -o jsonpath=&quot;{.items[0].metadata.name}&quot;)
 kubectl --namespace jenkins port-forward $POD_NAME 8080:8080
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Jenkins admin 계정의 암호를 확인합니다.&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; printf $(kubectl get secret --namespace jenkins jenkins-release -o jsonpath=&quot;{.data.jenkins-admin-password}&quot; | base64 --decode);echo
 xxxxx
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;이제 웹 브라우저에서 localhost:8080 로 접속해서 admin 계정으로 로그인합니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Jenkins 관리 &amp;gt; 시스템 설정 &amp;gt; &lt;code class=&quot;highlighter-rouge&quot;&gt;# of executors&lt;/code&gt;의 값을 10으로 변경하고 저장합니다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;credential-생성하기&quot;&gt;Credential 생성하기&lt;/h2&gt;

&lt;p&gt;DockerHub에 접속하기 위한 credential을 생성해보겠습니다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Jenkins UI에서 왼쪽 메뉴의 Credentials을 선택합니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;목록에서 Jenkins를 선택합니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Global credentials을 선택합니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;왼쪽 메뉴의 Add Credentials을 클릭합니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;DockerHub의 Username, Password를 입력하고 ID에 docker_credential을 입력합니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;OK 버튼을 선택해 저장합니다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;jenkins-pipeline-생성하기&quot;&gt;Jenkins Pipeline 생성하기&lt;/h2&gt;

&lt;p&gt;소스코드를 빌드하고 DockerHub에 저장하는 Pipeline을 생성해보겠습니다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;왼쪽 메뉴의 New Item을 선택합니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Item 이름을 sample-app으로 입력하고 Multibranch Pipeline을 선택합니다.
그리고 OK 버튼을 선택해 다음 화면으로 이동합니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;화면 상단의 General으로 이동합니다.
Display Name에 sample-app을 입력합니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Branch Sources로 이동합니다.
Add source &amp;gt; Git을 선택합니다. Project Repository에 앞에서 생성한 sample-app 저장소 주소를 입력합니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Scan Multibranch Pipeline Triggers로 이동합니다.
Periodically if not otherwise run를 체크하고 Interval을 1 minute로 선택합니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Save 버튼을 선택해 설정을 저장합니다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;sample-app-저장소에-소스코드-업로드&quot;&gt;sample-app 저장소에 소스코드 업로드&lt;/h2&gt;

&lt;p&gt;위에서 미리 생성한 sample-app 저장소에 소스코드를 업로드하겠습니다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;sample-app 디렉토리를 생성하고 jenkinsci-demo/sample-app의 소스코드를 복사합니다.&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; mkdir sample-app
 cd sample-app
 cp -r ../jenkinsci-demo/sample-app/. ./
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Jenkinsfile을 수정합니다.&lt;/p&gt;

    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;DOCKER_REPOSITORY&lt;/code&gt;를 위에서 생성한 DockerHub 저장소명으로 변경합니다.&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; def dockerCredential = &quot;docker_credential&quot;
 def imageTag = &quot;DOCKER_REPOSITORY:${env.BRANCH_NAME}.${env.BUILD_NUMBER}&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;소스코드를 저장소에 업로드합니다.&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; git init
 git add --all
 git commit -m &quot;first commit&quot;
 git remote add origin https://github.com/REPOSITORY_NAME/sample-app.git
 git push -u origin master
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Jenkins Pipeline 확인&lt;/p&gt;

    &lt;p&gt;소스코드가 업로드되면 Jenkins에서 master branch의 변경사항을 감지하고 Pipeline에 정의된 build job을 수행합니다.&lt;/p&gt;

    &lt;p&gt;Job이 성공적으로 수행되면 아래와 같은 화면을 확인할 수 있습니다.&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;/blog/assets/images/kubernetes/jenkins/jenkinsci-01.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Docker build 확인&lt;/p&gt;

    &lt;p&gt;Jenkins Pipeline 수행이 완료되면 Docker 이미지 저장소에서 빌드된 이미지를 확인할 수 있습니다.&lt;/p&gt;

    &lt;p&gt;이미지의 태그명은 &lt;code class=&quot;highlighter-rouge&quot;&gt;BRANCH_NAME.BUILD_NUMBER&lt;/code&gt;과 같이 정의됩니다.&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;/blog/assets/images/kubernetes/jenkins/jenkinsci-02.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;애플리케이션 확인&lt;/p&gt;

    &lt;p&gt;빌드한 Docker 이미지를 활용하여 애플리케이션을 실행해보겠습니다.&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; docker run -p 8080:8080 DOCKER_REPOSITORY_NAME/sample-app:BRANCH_NAME.BUILD_NUMBER
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;p&gt;애플리케이션이 실행되면 버전을 확인해봅니다.&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ curl localhost:8080/version
 0.1
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;branch-추가&quot;&gt;Branch 추가&lt;/h2&gt;

&lt;p&gt;이번에는 새로운 branch를 만들어 신규 기능을 추가해보겠습니다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;new_feature&lt;/code&gt; branch를 추가합니다.&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; git checkout -b new_feature
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Application version을 0.2로 변경합니다.&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ vi src/main/resources/application.yaml
 application:
     version: 0.2
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;변경사항을 Git 저장소에 반영합니다.&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; git add --all
 git commit -m &quot;Add new feature and Update version as 0.2&quot;
 git push origin new_feature
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Jenkins Pipeline 확인&lt;/p&gt;

    &lt;p&gt;소스코드가 업로드되면 Jenkins에서 new_feature branch의 변경사항을 감지하고 Pipeline에 정의된 build job을 수행합니다.&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;/blog/assets/images/kubernetes/jenkins/jenkinsci-03.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

    &lt;p&gt;Job이 성공적으로 수행되면 아래와 같은 화면을 확인할 수 있습니다.&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;/blog/assets/images/kubernetes/jenkins/jenkinsci-04.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Docker build 확인&lt;/p&gt;

    &lt;p&gt;Jenkins Pipeline 수행이 완료되면 Docker 이미지 저장소에서 빌드된 이미지를 확인할 수 있습니다.&lt;/p&gt;

    &lt;p&gt;이미지의 태그명은 &lt;code class=&quot;highlighter-rouge&quot;&gt;BRANCH_NAME.BUILD_NUMBER&lt;/code&gt;와 같이 정의됩니다.&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;/blog/assets/images/kubernetes/jenkins/jenkinsci-05.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;애플리케이션 확인&lt;/p&gt;

    &lt;p&gt;빌드한 Docker 이미지를 활용하여 애플리케이션을 실행해보겠습니다.&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; docker run -p 8080:8080 DOCKER_REPOSITORY_NAME/sample-app:BRANCH_NAME.BUILD_NUMBER
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;p&gt;애플리케이션이 실행되면 버전을 확인해봅니다.&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ curl localhost:8080/version
 0.2
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;compare--pull-request&quot;&gt;Compare &amp;amp; Pull request&lt;/h2&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;new_feature&lt;/code&gt; branch의 신규 기능을 Pull request 해보겠습니다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;새로운 branch가 추가되면 Compare &amp;amp; Pull request 알림이 나타납니다.
&lt;code class=&quot;highlighter-rouge&quot;&gt;Compare &amp;amp; Pull request&lt;/code&gt; 버튼을 선택합니다.&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;/blog/assets/images/kubernetes/jenkins/jenkinsci-06.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Merge하는 내용을 비교하고 이상이 없으면 &lt;code class=&quot;highlighter-rouge&quot;&gt;Create pull request&lt;/code&gt; 버튼을 선택합니다.&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;/blog/assets/images/kubernetes/jenkins/jenkinsci-07.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;merge-pull-request&quot;&gt;Merge pull request&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Pull request 목록에 방금 요청한 항목이 나타납니다.&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;/blog/assets/images/kubernetes/jenkins/jenkinsci-08.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;요청 항목에 문제가 없으면 &lt;code class=&quot;highlighter-rouge&quot;&gt;Merge pull request&lt;/code&gt; 버튼을 선택합니다.&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;/blog/assets/images/kubernetes/jenkins/jenkinsci-09.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;master branch에 new_feature 코드가 병합됩니다.
그리고 Jenkins Pipeline이 master branch의 변경사항을 감지하고 애플리케이션을 다시 빌드합니다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;</content><author><name>sj</name></author><category term="jenkinsci" /><category term="cicd" /><category term="devops" /><category term="kubernetes" /><summary type="html">Overview</summary></entry><entry><title type="html">Argo CD 설치하기</title><link href="http://localhost:4000/blog/cicd/2019/08/04/installing-argocd.html" rel="alternate" type="text/html" title="Argo CD 설치하기" /><published>2019-08-04T00:00:00+09:00</published><updated>2019-08-04T00:00:00+09:00</updated><id>http://localhost:4000/blog/cicd/2019/08/04/installing-argocd</id><content type="html" xml:base="http://localhost:4000/blog/cicd/2019/08/04/installing-argocd.html">&lt;h2 id=&quot;overview&quot;&gt;Overview&lt;/h2&gt;

&lt;p&gt;Argo CD는 지속적인 배포 환경을 구성하기 위한 툴입니다.&lt;/p&gt;

&lt;p&gt;이 문서에서는 Argo CD를 Kubernetes 환경에 구성하는 방법에 대해 알아보겠습니다.&lt;/p&gt;

&lt;h2 id=&quot;사전-준비&quot;&gt;사전 준비&lt;/h2&gt;

&lt;h3 id=&quot;kubernetes-클러스터-구성&quot;&gt;Kubernetes 클러스터 구성&lt;/h3&gt;

&lt;p&gt;Argo CD를 설치할 Kubernetes 클러스터 환경을 준비합니다.&lt;/p&gt;

&lt;h3 id=&quot;kubectl-cli-설치&quot;&gt;Kubectl CLI 설치&lt;/h3&gt;

&lt;p&gt;Argo CD를 설치하기 위해 kubectl cli를 설치합니다.&lt;/p&gt;

&lt;h2 id=&quot;argo-cd-설치&quot;&gt;Argo CD 설치&lt;/h2&gt;

&lt;p&gt;argocd namespace를 생성하고 kubectl 명령을 통해 argocd를 kubernetes cluster에 배포합니다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubectl create namespace argocd
kubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;정상적으로 배포되었는지 조회해봅니다.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubectl get po -n argocd
NAME                                             READY   STATUS    RESTARTS   AGE
argocd-application-controller-5576758b85-r45zq   1/1     Running   2          26m
argocd-dex-server-c87ff4c6-kgrcp                 1/1     Running   1          26m
argocd-redis-6f4db95c5-r5zbp                     1/1     Running   0          26m
argocd-repo-server-7dc5cc9b47-4m6ng              1/1     Running   0          26m
argocd-server-67c6bd95bc-7qdbl                   1/1     Running   0          26m
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;argo-cd-cli-설치&quot;&gt;Argo CD CLI 설치&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/argoproj/argo-cd/releases&quot;&gt;Argo CD Release&lt;/a&gt; 페이지에서 CLI 바이너리를 다운로드합니다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;//OSX
curl -LO https://github.com/argoproj/argo-cd/releases/download/[VERSION]/argocd-darwin-amd64
chmod u+x argocd-darwin-amd64
mv argocd-darwin-amd64 /usr/local/bin/argocd

//Linux
curl -LO https://github.com/argoproj/argo-cd/releases/download/[VERSION]/argocd-linux-amd64
chmod u+x argocd-linux-amd64
mv argocd-linux-amd64 /usr/local/bin/argocd
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;argo-cd-api-서버에-접속하기&quot;&gt;Argo CD API 서버에 접속하기&lt;/h2&gt;

&lt;p&gt;Argo CD 설치 시 기본 설정은 API 서버를 외부 주소로 노출시키지 않습니다.&lt;/p&gt;

&lt;p&gt;아래와 같이 세 가지 방법으로 API 서버를 외부에서 접속할 수 있습니다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Service Type을 Load Balancer로 설정&lt;/p&gt;

    &lt;p&gt;아래 명령을 실행하여 Service Type을 Load Balancer로 설정합니다.&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; kubectl patch svc argocd-server -n argocd -p '{&quot;spec&quot;: {&quot;type&quot;: &quot;LoadBalancer&quot;}}'
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Ingress 설정&lt;/p&gt;

    &lt;p&gt;아래 가이드를 참고하여 Ingress를 설정합니다.&lt;/p&gt;

    &lt;p&gt;https://argoproj.github.io/argo-cd/operator-manual/ingress/&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Port Forwarding 설정&lt;/p&gt;

    &lt;p&gt;아래 명령을 실행하여 Port Forwarding을 설정합니다.&lt;/p&gt;

    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;http://localhost:8080&lt;/code&gt;으로 서버에 접속할 수 있습니다.&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; kubectl port-forward svc/argocd-server -n argocd 8080:443
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;로그인&quot;&gt;로그인&lt;/h2&gt;

&lt;p&gt;Argo CD의 admin 계정 암호는 argocd-server pod 이름으로 자동 설정됩니다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubectl get pods -n argocd -l app.kubernetes.io/name=argocd-server -o name | cut -d'/' -f 2
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;위의 암호를 사용하여 admin으로 로그입합니다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;argocd login [SERVER_ADDRESS]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;아래 명령을 실행하여 패스워드를 변경합니다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;argocd account update-password
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;웹 브라우저를 통해서도 서버에 접속할 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/images/kubernetes/argocd/installing-argocd-login.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;샘플-애플리케이션-배포&quot;&gt;샘플 애플리케이션 배포&lt;/h2&gt;

&lt;p&gt;이제 Argo CD를 활용하여 샘플 애플리케이션을 배포해보겠습니다.&lt;/p&gt;

&lt;h3 id=&quot;cli-사용&quot;&gt;CLI 사용&lt;/h3&gt;

&lt;p&gt;Argo CD CLI를 사용하여 샘플 애플리케이션을 배포합니다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;아래 명령을 실행하여 샘플 애플리케이션을 생성합니다.&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; argocd app create sample-app \
 --repo https://github.com/argoproj/argocd-example-apps.git \
 --path guestbook \
 --dest-server https://kubernetes.default.svc \
 --dest-namespace default
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;생성한 sample-app을 조회해보면 STATUS가 OutOfSync입니다.&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ argocd app get sample-app
 Name:               guestbook
 Server:             https://kubernetes.default.svc
 Namespace:          default
 ...
 GROUP  KIND        NAMESPACE  NAME          STATUS     HEALTH
 apps   Deployment  default    guestbook-ui  OutOfSync  Missing
     Service     default    guestbook-ui  OutOfSync  Missing
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;아래 명령을 실행하여 sample-app을 동기화합니다.
동기화하면 kubectl apply 명령을 실행해 애플리케이션을 클러스터에 배포합니다.&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; argocd app sync guestbook
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;ui-활용&quot;&gt;UI 활용&lt;/h3&gt;

&lt;p&gt;웹 브라우저에서 Argo CD UI를 통해 샘플 애플리케이션을 배포해보겠습니다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Create Application 버튼을 선택합니다.&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;/blog/assets/images/kubernetes/argocd/installing-argocd-deploy-00.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Application Name에 sample-app, Project는 default를 선택합니다.&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;/blog/assets/images/kubernetes/argocd/installing-argocd-deploy-01.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Repository URL에 https://github.com/argoproj/argocd-example-apps.git 를 입력합니다.
Revision은 Head, Path는 guestbook을 입력합니다.&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;/blog/assets/images/kubernetes/argocd/installing-argocd-deploy-02.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Cluster URL은 https://kubernetes.default.svc, Namespace는 default를 선택합니다.
그리고 화면 상단의 Create 버튼을 선택해 애플리케이션을 생성합니다.&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;/blog/assets/images/kubernetes/argocd/installing-argocd-deploy-03.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;처음 배포하면 Status가 OutOfSync 상태입니다. Sync 버튼을 선택해 동기화합니다.
동기화하면 kubectl apply 명령을 실행해 애플리케이션을 클러스터에 배포합니다.&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;/blog/assets/images/kubernetes/argocd/installing-argocd-deploy-04.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;배포가 완료되면 아래와 같은 모습니다.&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;/blog/assets/images/kubernetes/argocd/installing-argocd-deploy-05.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;</content><author><name>sj</name></author><category term="argocd" /><category term="cicd" /><category term="devops" /><category term="kubernetes" /><summary type="html">Overview</summary></entry><entry><title type="html">CircleCI를 활용한 코드 통합, 빌드, 배포 파이프라인 구성하기</title><link href="http://localhost:4000/blog/cicd/2019/07/03/circleci.html" rel="alternate" type="text/html" title="CircleCI를 활용한 코드 통합, 빌드, 배포 파이프라인 구성하기" /><published>2019-07-03T00:00:00+09:00</published><updated>2019-07-03T00:00:00+09:00</updated><id>http://localhost:4000/blog/cicd/2019/07/03/circleci</id><content type="html" xml:base="http://localhost:4000/blog/cicd/2019/07/03/circleci.html">&lt;h2 id=&quot;overview&quot;&gt;Overview&lt;/h2&gt;

&lt;p&gt;CircleCI는 소스코드를 통합하고 빌드, 배포를 자동화하는 파이프라인을 구성하기 위한 툴입니다.&lt;/p&gt;

&lt;p&gt;이 문서에서는 아래와 같은 서비스를 통합하여 CI/CD 환경을 구성해보겠습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;형상 관리: Github&lt;/li&gt;
  &lt;li&gt;빌드, 배포, 파이프라인: Circle CI&lt;/li&gt;
  &lt;li&gt;이미지 저장소: AWS ECR(Elastic Container Registry)&lt;/li&gt;
  &lt;li&gt;애플리케이션 서버: AWS ECS(Elastic Container Service) Fargate&lt;/li&gt;
  &lt;li&gt;알림: Slack&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/images/cloud/circleci/circleci_architecture.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;사전-준비&quot;&gt;사전 준비&lt;/h2&gt;

&lt;h3 id=&quot;샘플-코드-준비하기&quot;&gt;샘플 코드 준비하기&lt;/h3&gt;

&lt;p&gt;이 문서에서는 &lt;a href=&quot;https://github.com/YunSangJun/circleci-demo&quot;&gt;circleci-demo&lt;/a&gt; 프로젝트를 활용하겠습니다.&lt;/p&gt;

&lt;p&gt;위 프로젝트를 자신의 Github 계정으로 fork합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/images/cloud/circleci/circleci-prep-code.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;aws-ecrelastic-container-registry-구성&quot;&gt;AWS ECR(Elastic Container Registry) 구성&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;/blog/cloud/2019/06/21/aws-cicd03.html&quot;&gt;AWS에서 CI/CD 환경 구성 #3 - 코드 빌드, CodeBuild&lt;/a&gt;
문서의 &lt;code class=&quot;highlighter-rouge&quot;&gt;사전 준비 &amp;gt; ECR(Elastic Container Registry) 생성&lt;/code&gt; 섹션을 참고하여 ECR을 생성하겠습니다.&lt;/p&gt;

&lt;p class=&quot;tip-title&quot;&gt;참고&lt;/p&gt;
&lt;p class=&quot;tip-content&quot;&gt;
ECR 이름은 `circleci-demo`로 생성하겠습니다.
&lt;/p&gt;

&lt;h3 id=&quot;ecr에-샘플-코드-이미지-저장&quot;&gt;ECR에 샘플 코드 이미지 저장&lt;/h3&gt;

&lt;p&gt;위에서 fork한 프로젝트를 로컬로 복제합니다.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ git clone REPOSITORY_URL
$ cd circleci-demo
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Maven 빌드 명령을 실행해 jar 파일을 생성합니다.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ mvn clean package
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Docker 빌드 명령을 실행해 Docker 이미지를 생성합니다. 
AWS_ACCOUNT_ID, AWS_DEFAULT_REGION는 자신의 AWS 환경 정보를 입력합니다.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ export ECR_REPOSITORY_NAME=&quot;circleci-demo&quot;
$ export AWS_ACCOUNT_ID=&quot;xxx&quot;
$ export AWS_DEFAULT_REGION=&quot;xxx&quot;
$ export FULL_IMAGE_NAME=&quot;${AWS_ACCOUNT_ID}.dkr.ecr.${AWS_DEFAULT_REGION}.amazonaws.com/${ECR_REPOSITORY_NAME}:latest&quot;
$ docker build -t $FULL_IMAGE_NAME .
$ docker images
REPOSITORY                                    TAG                 IMAGE ID            CREATED             SIZE
xxx.dkr.ecr.xxx.amazonaws.com/circleci-demo   latest              d692168175e6        2 minutes ago       122MB
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;ECR에 로그인하고 Docker 이미지를 ECR에 저장합니다.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ eval $(aws ecr get-login --region $AWS_DEFAULT_REGION --no-include-email)
$ docker push $FULL_IMAGE_NAME
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;ECR Console에 접속해서 circleci-demo 저장소로 이동해 위에서 저장한 이미지의 주소를 복사해둡니다.
이 주소는 아래 ECS Task 구성시 사용하겠습니다.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;xxx.dkr.ecr.xxx.amazonaws.com/circleci-demo:latest&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&quot;aws-ecs-cluster-구성&quot;&gt;AWS ECS Cluster 구성&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;/blog/cloud/2019/06/23/aws-ecs-01.html&quot;&gt;AWS ECS 구성 및 활용하기 #1 - 사전 준비 및 클러스터 생성하기&lt;/a&gt; 
문서의 &lt;code class=&quot;highlighter-rouge&quot;&gt;ECS Cluster 생성&lt;/code&gt; 섹션을 참고하여 클러스터를 생성하겠습니다.&lt;/p&gt;

&lt;p class=&quot;tip-title&quot;&gt;참고&lt;/p&gt;
&lt;p class=&quot;tip-content&quot;&gt;
클러스터 이름은 `circleci-demo`로 생성하겠습니다.
&lt;/p&gt;

&lt;h3 id=&quot;aws-ecs-task-구성&quot;&gt;AWS ECS Task 구성&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;/blog/cloud/2019/06/23/aws-ecs-02.html&quot;&gt;AWS ECS 구성 및 활용하기 #2 - 작업 정의 구성하기(ECS Task)&lt;/a&gt;
문서를 참고하여 작업 정의를 생성하겠습니다.&lt;/p&gt;

&lt;p class=&quot;tip-title&quot;&gt;참고&lt;/p&gt;
&lt;p class=&quot;tip-content&quot;&gt;
작업 정의 이름은 `circleci-demo`로 생성하겠습니다.&lt;br /&gt;
컨테이너 이미지 주소는 `ECR에 샘플 코드 이미지 저장` 섹션에서 복사해둔 주소를 입력하겠습니다.
&lt;/p&gt;

&lt;h3 id=&quot;aws-ecs-service-구성&quot;&gt;AWS ECS Service 구성&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;/blog/cloud/2019/06/23/aws-ecs-03.html&quot;&gt;AWS ECS 구성 및 활용하기 #3 - 서비스(ECS Service) 구성하기&lt;/a&gt;
문서를 참고하여 ECS 서비스를 구성하겠습니다.&lt;/p&gt;

&lt;p class=&quot;tip-title&quot;&gt;참고&lt;/p&gt;
&lt;p class=&quot;tip-content&quot;&gt;
서비스 이름은 `circleci-demo`로 생성하겠습니다.
&lt;/p&gt;

&lt;h2 id=&quot;circleci에-빌드-및-배포-구성하기&quot;&gt;CircleCI에 빌드 및 배포 구성하기&lt;/h2&gt;

&lt;h3 id=&quot;circleci에-접속하기&quot;&gt;CircleCI에 접속하기&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://circleci.com&quot;&gt;CircleCI 콘솔&lt;/a&gt;에 접속합니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;화면 상단 오른쪽의 &lt;code class=&quot;highlighter-rouge&quot;&gt;Log In&lt;/code&gt; 버튼을 선택합니다.
&lt;img src=&quot;/blog/assets/images/cloud/circleci/circleci-login-01.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Log In with GitHub&lt;/code&gt; 버튼을 선택해 자신의 Github 계정으로 로그인하겠습니다. 
&lt;img src=&quot;/blog/assets/images/cloud/circleci/circleci-login-02.png&quot; alt=&quot;&quot; width=&quot;40%&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;github-프로젝트-연동하기&quot;&gt;Github 프로젝트 연동하기&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;CircleCI Console에 접속 &amp;gt; 왼쪽 메뉴의 Add Project 선택&lt;/li&gt;
  &lt;li&gt;Project 리스트 &amp;gt; &lt;code class=&quot;highlighter-rouge&quot;&gt;circleci-demo&lt;/code&gt; &amp;gt; &lt;code class=&quot;highlighter-rouge&quot;&gt;Set Up Project&lt;/code&gt; 버튼 선택
&lt;img src=&quot;/blog/assets/images/cloud/circleci/circleci-add-project-01.png&quot; alt=&quot;&quot; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;프로젝트-설정하기&quot;&gt;프로젝트 설정하기&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Settings &amp;gt; Organization &amp;gt; Projects &amp;gt; Followed projects &amp;gt; &lt;code class=&quot;highlighter-rouge&quot;&gt;circleci-demo&lt;/code&gt; &amp;gt; 설정 버튼(톱니바퀴 아이콘) 선택
&lt;img src=&quot;/blog/assets/images/cloud/circleci/circleci-setup.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Permissions &amp;gt; AWS Permissions &amp;gt; Access Key ID, Secret Access Key 입력
&lt;img src=&quot;/blog/assets/images/cloud/circleci/circleci-aws-permission.png&quot; alt=&quot;&quot; width=&quot;70%&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Permissions &amp;gt; Build Settings &amp;gt; Environment Variables &amp;gt; 아래 환경 변수 입력&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;/blog/assets/images/cloud/circleci/circleci-env.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;이름&lt;/td&gt;
          &lt;td&gt;값&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
          &lt;td&gt;AWS_ACCOUNT_ID&lt;/td&gt;
          &lt;td&gt;계정 아이디&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
          &lt;td&gt;AWS_DEFAULT_REGION&lt;/td&gt;
          &lt;td&gt;리전 이름&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
          &lt;td&gt;AWS_RESOURCE_NAME_PREFIX&lt;/td&gt;
          &lt;td&gt;circleci-demo&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;빌드-및-배포-설정하기&quot;&gt;빌드 및 배포 설정하기&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;circleci-demo&lt;/code&gt; 프로젝트 root에 &lt;code class=&quot;highlighter-rouge&quot;&gt;.circleci&lt;/code&gt; 디렉토리를 생성합니다.&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ mkdir .circleci
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;.circleci&lt;/code&gt; 디렉토리 하위에 &lt;code class=&quot;highlighter-rouge&quot;&gt;config.yml&lt;/code&gt; 파일을 생성하고 단계별로 설정해보겠습니다.&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ vi .circleci/config.yml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;p&gt;먼저 Version을 설정합니다.&lt;/p&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;version: 2.1
...
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;p&gt;다음으로 Orbs를 설정합니다. Orbs는 CircleCI 플랫폼을 빠르게 사용할 수 있도록 도와주는 패키지입니다. 
&lt;code class=&quot;highlighter-rouge&quot;&gt;aws-cli&lt;/code&gt;와 &lt;code class=&quot;highlighter-rouge&quot;&gt;aws-ecs&lt;/code&gt; 패키지를 설정하겠습니다.&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;...
orbs:
  aws-cli: circleci/aws-cli@0.1.4
  aws-ecs: circleci/aws-ecs@0.0.3
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;p&gt;working directory를 Home의 circleci-demo 디렉토리로 설정합니다.&lt;/p&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;...
jobs:
  build:
    ...
    working_directory: ~/circleci-demo
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;p&gt;빌드 서버로 사용할 컨테이너의 base image를 설정합니다.&lt;/p&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;...
jobs:
  build:
    ...
    docker:
    - image: circleci/openjdk:8-jdk-browsers
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;p&gt;소스코드를 체크아웃하겠습니다.&lt;/p&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;...
jobs:
  build:
    ...
    steps:
      - checkout
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;p&gt;Remote에 있는 Docker 데몬을 사용하도록 설정하겠습니다. 
빌드 서버로 사용할 컨테이너에는 Docker 클라이언트 툴만 설치하고 실제 빌드는 Remote에 있는 Docker 데몬을 사용합나디.&lt;/p&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;...
jobs:
  build:
    ...
    steps:
      ...
      - setup_remote_docker
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;p&gt;저장된 프로젝트 의존성 라이브러리의 캐시가 있는 경우 복구합니다.&lt;/p&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;...
jobs:
  build:
    ...
    steps:
      ...
      - restore_cache:
          key: circleci-demo-        
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;p&gt;프로젝트 의존성 라이브러리를 다운로드합니다.&lt;/p&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;...
jobs:
  build:
    ...
    steps:
      ...
      - run: mvn dependency:go-offline  
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;p&gt;다운로드한 프로젝트 의존성 라이브러리를 캐싱합니다.&lt;/p&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;...
jobs:
  build:
    ...
    steps:
      ...
      - save_cache:
          paths:
            - ~/.m2
          key: circleci-demo-
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;p&gt;소스코드를 Maven 빌드해 JAR 파일을 생성합니다.&lt;/p&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;...
jobs:
  build:
    ...
    steps:
      ...
      - run: mvn package
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;p&gt;빌드 테스트 결과를 저장할 경로를 지정합니다.&lt;/p&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;...
jobs:
  build:
    ...
    steps:
      ...
      - store_test_results:
          path: target/surefire-reports
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;p&gt;빌드 결과물인 JAR 파일의 저장 경로를 설정합니다.&lt;/p&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;...
jobs:
  build:
    ...
    steps:
      ...
      - store_artifacts:
          path: target/circleci-demo-0.0.1-SNAPSHOT.jar
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;p&gt;ECR의 이미지 경로를 환경 변수로 설정합니다.&lt;/p&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;...
jobs:
  build:
    ...
    steps:
      ...
      - run:
          name: Setup common environment variables
          command: |
            echo 'export ECR_REPOSITORY_NAME=&quot;${AWS_RESOURCE_NAME_PREFIX}&quot;' &amp;gt;&amp;gt; $BASH_ENV
            echo 'export FULL_IMAGE_NAME=&quot;${AWS_ACCOUNT_ID}.dkr.ecr.${AWS_DEFAULT_REGION}.amazonaws.com/${ECR_REPOSITORY_NAME}:${CIRCLE_SHA1}&quot;' &amp;gt;&amp;gt; $BASH_ENV
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;p&gt;빌드한 JAR 파일을 구동할 Docker 이미지를 빌드합니다.&lt;/p&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;...
jobs:
  build:
    ...
    steps:
      ...
      - run:
          name: Build image
          command: |
            docker build -t $FULL_IMAGE_NAME .
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;p&gt;빌드한 Docker 이미지가 정상 동작하는지 테스트합니다.&lt;/p&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;...
jobs:
  build:
    ...
    steps:
      ...
      - run:
          name: Test image
          command: |
            docker run -d -p 8080:8080 --name built-image $FULL_IMAGE_NAME
            sleep 10
            docker run --network container:built-image appropriate/curl --retry 10 --retry-connrefused http://localhost:8080 | grep &quot;Hello World&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;p&gt;빌드한 Docker 이미지를 아카이브(TAR) 파일로 저장합니다.&lt;/p&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;...
jobs:
  build:
    ...
    steps:
      ...
      - run:
          name: Save image to an archive
          command: |
            mkdir docker-image
            docker save -o docker-image/image.tar $FULL_IMAGE_NAME
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;p&gt;Workflow의 다음 단계에서 사용할 임시 파일을 영구적으로 저장하기 위한 설정을합니다.&lt;/p&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;...
jobs:
  build:
    ...
    steps:
      ...
      - persist_to_workspace:
          root: .
          paths:
            - docker-image
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;p&gt;다음으로 배포(deploy) 설정을 하겠습니다. 
배포 서버로 사용할 컨테이너 이미지를 설정합니다.&lt;/p&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;...
jobs:
  build:
    ...
  deploy:  
    docker:
      - image: circleci/python:3.6.1
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;p&gt;AWS 클라이언트 툴 사용 시 결과 출력의 포맷을 JSON으로 설정합니다.&lt;/p&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;...
jobs:
  build:
    ...
  deploy: 
    ...
    environment:
      AWS_DEFAULT_OUTPUT: json
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;p&gt;소스코드를 체크아웃하겠습니다.&lt;/p&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;...
jobs:
  build:
    ...
  deploy:
    ...
    steps:
      - checkout
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;p&gt;Remote에 있는 Docker 데몬을 사용하도록 설정하겠습니다.&lt;/p&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;...
jobs:
  build:
    ...
  deploy:
    ...
    steps:
      ...
      - setup_remote_docker
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;p&gt;워크플로우의 workspace를 배포 서버로 사용하는 컨테이너에 연결합니다.&lt;/p&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;...
jobs:
  build:
    ...
  deploy:
    ...
    steps:
      ...
      - attach_workspace:
          at: workspace
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;p&gt;컨테이너에 AWS CLI(Command Line Interface)를 설치합니다.&lt;/p&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;...
jobs:
  build:
    ...
  deploy:
    ...
    steps:
      ...
      - aws-cli/install
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;p&gt;AWS CLI를 사용하기 위해 Access key와 Region 정보를 설정합니다.&lt;/p&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;...
jobs:
  build:
    ...
  deploy:
    ...
    steps:
      ...
      - aws-cli/configure:
          aws-access-key-id: &quot;$AWS_ACCESS_KEY_ID&quot;
          aws-region: &quot;$AWS_DEFAULT_REGION&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;p&gt;빌드 과정에서 저장한 Docker 이미지를 로드합니다.&lt;/p&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;...
jobs:
  build:
    ...
  deploy:
    ...
    steps:
      ...
      - run:
          name: Load image
          command: |
            docker load --input workspace/docker-image/image.tar
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;p&gt;ECS 및 이미지 환경 변수를 설정합니다.
&lt;code class=&quot;highlighter-rouge&quot;&gt;AWS_RESOURCE_NAME_PREFIX&lt;/code&gt;와 같은 변수는 앞의 프로젝트 설정에서 저장한 값이 주입됩니다.&lt;/p&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;...
jobs:
  build:
    ...
  deploy:
    ...
    steps:
      ...
      - run:
          name: Setup common environment variables
          command: |
            echo 'export ECS_CLUSTER_NAME=&quot;${AWS_RESOURCE_NAME_PREFIX}&quot;' &amp;gt;&amp;gt; $BASH_ENV
            echo 'export ECS_SERVICE_NAME=&quot;${AWS_RESOURCE_NAME_PREFIX}&quot;' &amp;gt;&amp;gt; $BASH_ENV
            echo 'export FULL_IMAGE_NAME=&quot;${AWS_ACCOUNT_ID}.dkr.ecr.${AWS_DEFAULT_REGION}.amazonaws.com/${AWS_RESOURCE_NAME_PREFIX}:${CIRCLE_SHA1}&quot;' &amp;gt;&amp;gt; $BASH_ENV
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;p&gt;ECR에 로그인하고 Docker 이미지를 push합니다.&lt;/p&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;...
jobs:
  build:
    ...
  deploy:
    ...
    steps:
      ...
      - run:
          name: Push image
          command: |
            eval $(aws ecr get-login --region $AWS_DEFAULT_REGION --no-include-email)
            docker push $FULL_IMAGE_NAME
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;p&gt;ECS 서비스를 업데이트합니다.
기존 이미지를 새로 빌드한 Docker 이미지로 빌드합니다.&lt;/p&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;...
jobs:
  build:
    ...
  deploy:
    ...
    steps:
      ...
      - aws-ecs/update-service:
          family: &quot;${ECS_SERVICE_NAME}&quot;
          cluster-name: &quot;${ECS_CLUSTER_NAME}&quot;
          container-image-name-updates: &quot;container=${ECS_SERVICE_NAME},image-and-tag=${FULL_IMAGE_NAME}&quot;
          verify-revision-is-deployed: true
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;p&gt;배포한 ECS 서비스가 정상 동작하는지 테스트합니다.&lt;/p&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;...
jobs:
  build:
    ...
  deploy:
    ...
    steps:
      ...
      - run:
          name: Test deployment (Please manually tear down AWS resources after use, if desired)
          command: |
            TARGET_GROUP_ARN=$(aws ecs describe-services --cluster $ECS_CLUSTER_NAME --services $ECS_SERVICE_NAME | jq -r '.services[0].loadBalancers[0].targetGroupArn')
            ELB_ARN=$(aws elbv2 describe-target-groups --target-group-arns $TARGET_GROUP_ARN | jq -r '.TargetGroups[0].LoadBalancerArns[0]')
            ELB_DNS_NAME=$(aws elbv2 describe-load-balancers --load-balancer-arns $ELB_ARN | jq -r '.LoadBalancers[0].DNSName')
            for attempt in {1..50}; do
              curl -s --retry 10 http://$ELB_DNS_NAME | grep -E &quot;Hello World&quot;
            done
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;p&gt;workflows를 설정합니다.
앞선 과정의 build 및 deploy를 순차적으로 실행합니다.
filters를 설정해 Github의 master 브랜치에 변경이 있는 경우에만 빌드를 하도록합니다.&lt;/p&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;...
jobs:
  build:
    ...
  deploy:
    ...
workflows:
  version: 2
  build-deploy:
    jobs:
      - build:
          filters:
            branches:
              only: master
      - deploy:
          requires:
            - build
          filters:
            branches:
              only: master
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;전체-설정-코드&quot;&gt;전체 설정 코드&lt;/h3&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;version: 2.1
orbs:
  aws-cli: circleci/aws-cli@0.1.4
  aws-ecs: circleci/aws-ecs@0.0.3
jobs:
  build:
    working_directory: ~/circleci-demo

    docker:
      - image: circleci/openjdk:8-jdk-browsers

    steps:
      - checkout
      - setup_remote_docker

      - restore_cache:
          key: circleci-demo-
      
      - run: mvn dependency:go-offline
      
      - save_cache:
          paths:
            - ~/.m2
          key: circleci-demo-
      
      - run: mvn package
      
      - store_test_results:
          path: target/surefire-reports
      
      - store_artifacts:
          path: target/circleci-demo-0.0.1-SNAPSHOT.jar

      - run:
          name: Setup common environment variables
          command: |
            echo 'export ECR_REPOSITORY_NAME=&quot;${AWS_RESOURCE_NAME_PREFIX}&quot;' &amp;gt;&amp;gt; $BASH_ENV
            echo 'export FULL_IMAGE_NAME=&quot;${AWS_ACCOUNT_ID}.dkr.ecr.${AWS_DEFAULT_REGION}.amazonaws.com/${ECR_REPOSITORY_NAME}:${CIRCLE_SHA1}&quot;' &amp;gt;&amp;gt; $BASH_ENV
      
      - run:
          name: Build image
          command: |
            docker build -t $FULL_IMAGE_NAME .

      - run:
          name: Test image
          command: |
            docker run -d -p 8080:8080 --name built-image $FULL_IMAGE_NAME
            sleep 10
            docker run --network container:built-image appropriate/curl --retry 10 --retry-connrefused http://localhost:8080 | grep &quot;Hello World&quot;
      
      - run:
          name: Save image to an archive
          command: |
            mkdir docker-image
            docker save -o docker-image/image.tar $FULL_IMAGE_NAME
            
      - persist_to_workspace:
          root: .
          paths:
            - docker-image
  deploy:  
    docker:
      - image: circleci/python:3.6.1
    environment:
      AWS_DEFAULT_OUTPUT: json
    steps:
      - checkout
      - setup_remote_docker
      - attach_workspace:
          at: workspace
      - aws-cli/install
      - aws-cli/configure:
          aws-access-key-id: &quot;$AWS_ACCESS_KEY_ID&quot;
          aws-region: &quot;$AWS_DEFAULT_REGION&quot;
      - run:
          name: Load image
          command: |
            docker load --input workspace/docker-image/image.tar
      - run:
          name: Setup common environment variables
          command: |
            echo 'export ECS_CLUSTER_NAME=&quot;${AWS_RESOURCE_NAME_PREFIX}&quot;' &amp;gt;&amp;gt; $BASH_ENV
            echo 'export ECS_SERVICE_NAME=&quot;${AWS_RESOURCE_NAME_PREFIX}&quot;' &amp;gt;&amp;gt; $BASH_ENV
            echo 'export FULL_IMAGE_NAME=&quot;${AWS_ACCOUNT_ID}.dkr.ecr.${AWS_DEFAULT_REGION}.amazonaws.com/${AWS_RESOURCE_NAME_PREFIX}:${CIRCLE_SHA1}&quot;' &amp;gt;&amp;gt; $BASH_ENV
      - run:
          name: Push image
          command: |
            eval $(aws ecr get-login --region $AWS_DEFAULT_REGION --no-include-email)
            docker push $FULL_IMAGE_NAME
      - aws-ecs/update-service:
          family: &quot;${ECS_SERVICE_NAME}&quot;
          cluster-name: &quot;${ECS_CLUSTER_NAME}&quot;
          container-image-name-updates: &quot;container=${ECS_SERVICE_NAME},image-and-tag=${FULL_IMAGE_NAME}&quot;
          verify-revision-is-deployed: true
      - run:
          name: Test deployment (Please manually tear down AWS resources after use, if desired)
          command: |
            TARGET_GROUP_ARN=$(aws ecs describe-services --cluster $ECS_CLUSTER_NAME --services $ECS_SERVICE_NAME | jq -r '.services[0].loadBalancers[0].targetGroupArn')
            ELB_ARN=$(aws elbv2 describe-target-groups --target-group-arns $TARGET_GROUP_ARN | jq -r '.TargetGroups[0].LoadBalancerArns[0]')
            ELB_DNS_NAME=$(aws elbv2 describe-load-balancers --load-balancer-arns $ELB_ARN | jq -r '.LoadBalancers[0].DNSName')
            for attempt in {1..50}; do
              curl -s --retry 10 http://$ELB_DNS_NAME | grep -E &quot;Hello World&quot;
            done
workflows:
  version: 2
  build-deploy:
    jobs:
      - build:
          filters:
            branches:
              only: master
      - deploy:
          requires:
            - build
          filters:
            branches:
              only: master
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;변경사항-반영&quot;&gt;변경사항 반영&lt;/h3&gt;

&lt;p&gt;변경사항을 Github에 반영합니다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ git add --all
$ git commit -m &quot;Updated circleci configuration&quot;
$ git push
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;빌드-및-배포-상태-확인&quot;&gt;빌드 및 배포 상태 확인&lt;/h3&gt;

&lt;p&gt;Github에 변경사항이 발생하면 CircleCI에서 이를 감지하여 빌드 및 배포를 수행합니다.&lt;/p&gt;

&lt;p&gt;CicleCI 콘솔에서 Workflows 메뉴를 선택하면 빌드 및 배포 상태를 확인할 수 있습니다.
빌드 또는 배포 상태를 선택하면 해당 Job의 상세 정보를 확인할 수 있습니다.
&lt;img src=&quot;/blog/assets/images/cloud/circleci/circleci-workflows.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;CicleCI 콘솔에서 Jobs 메뉴를 선택하면 실행 또는 완료된 Job의 목록을 확인할 수 있습니다.
&lt;img src=&quot;/blog/assets/images/cloud/circleci/circleci-jobs-01.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;목록에서 Job을 선택하면 상세정보를 확인할 수 있습니다.&lt;br /&gt;
&lt;img src=&quot;/blog/assets/images/cloud/circleci/circleci-jobs-02.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Deploy job의 마지막 단계인 Test deployment 로그를 확인해보면 ECS 서비스가 정상적으로 
배포되었는지 테스트하는 로그를 확인할 수 있습니다.
&lt;code class=&quot;highlighter-rouge&quot;&gt;Hello World(Version 1)&lt;/code&gt; 메세지가 계속 출력되면 배포가 정상적으로 완료된것입니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/images/cloud/circleci/circleci-jobs-03.png&quot; alt=&quot;&quot; width=&quot;80%&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;slack-연동&quot;&gt;Slack 연동&lt;/h3&gt;

&lt;p&gt;다음으로 CircleCI를 Slack Chat 서비스와 연동하여 빌드 및 배포 성공/실패에 대한 알람을 받을 수 있도록 설정해보겠습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://api.slack.com/apps&quot;&gt;Slack MyApp&lt;/a&gt; 페이지에 접속합니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Create New App 버튼을 선택합니다.
&lt;img src=&quot;/blog/assets/images/cloud/circleci/circleci-slack-01.png&quot; alt=&quot;&quot; width=&quot;80%&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;App Name에 circleci-demo를 입력하고 Slack workspace를 선택한뒤 Create App 버튼은 선택합니다.
&lt;img src=&quot;/blog/assets/images/cloud/circleci/circleci-slack-02.png&quot; alt=&quot;&quot; width=&quot;60%&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Slack 메신저에서 circleci-demo 채널을 생성합니다.
&lt;img src=&quot;/blog/assets/images/cloud/circleci/circleci-slack-03.png&quot; alt=&quot;&quot; width=&quot;60%&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;다시 Slack MyApp 페이지로 돌아와서 생성한 circleci-demo 앱을 선택합니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Features &amp;gt; Incoming Webhooks &amp;gt; Activate Incoming Webhooks를 On으로 변경합니다.
&lt;img src=&quot;/blog/assets/images/cloud/circleci/circleci-slack-04.png&quot; alt=&quot;&quot; width=&quot;80%&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;하단의 Webhook URL의 Add New Webhook to Workspace 버튼을 선택합니다. 
&lt;img src=&quot;/blog/assets/images/cloud/circleci/circleci-slack-05.png&quot; alt=&quot;&quot; width=&quot;80%&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Post to에서 circleci-demo 채널을 선택하고 Install 버튼을 선택합니다.
&lt;img src=&quot;/blog/assets/images/cloud/circleci/circleci-slack-06.png&quot; alt=&quot;&quot; width=&quot;40%&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;생성된 Webhook URL을 복사해둡니다.
&lt;img src=&quot;/blog/assets/images/cloud/circleci/circleci-slack-07.png&quot; alt=&quot;&quot; width=&quot;80%&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;다시 CircleCI 콘솔로 이동해서 프로젝트 설정 화면으로 이동합니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Notifications &amp;gt; Chat Notifications &amp;gt; Webhook URL에 복사해둔 URL을 붙여넣고 저장합니다.
&lt;img src=&quot;/blog/assets/images/cloud/circleci/circleci-slack-08.png&quot; alt=&quot;&quot; width=&quot;60%&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;이제 소스코드를 수정해서 빌드 및 배포를 다시 실행해보겠습니다. 
아래 파일에서 Version을 2로 변경하고 Commit &amp;amp; Push합니다.&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;lt;circleci-demo/src/main/java/com/example/demo/HomeRestController.java&amp;gt;
...
  @RequestMapping(value = &quot;/&quot;, method = RequestMethod.GET)
  public String getHome() {
    return &quot;Hello World(Version 2)&quot;; 
  }
...
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;CircleCI에서 소스 변경을 감지하고 빌드 및 배포 Job을 실행합니다. 
완료 되면 아래와 같이 Slack 채널에 빌드 및 배포 성공을 알리는 메세지가 출력됩니다.&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;/blog/assets/images/cloud/circleci/circleci-slack-09.png&quot; alt=&quot;&quot; width=&quot;70%&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>sj</name></author><category term="circleci" /><category term="cicd" /><category term="devops" /><summary type="html">Overview</summary></entry><entry><title type="html">AWS ECS 구성 및 활용하기 #3 - 서비스(ECS Service) 구성하기</title><link href="http://localhost:4000/blog/cloud/2019/06/23/aws-ecs-03.html" rel="alternate" type="text/html" title="AWS ECS 구성 및 활용하기 #3 - 서비스(ECS Service) 구성하기" /><published>2019-06-23T00:00:00+09:00</published><updated>2019-06-23T00:00:00+09:00</updated><id>http://localhost:4000/blog/cloud/2019/06/23/aws-ecs-03</id><content type="html" xml:base="http://localhost:4000/blog/cloud/2019/06/23/aws-ecs-03.html">&lt;p&gt;AWS에서 ECS(Elastic Container Service)의 서비스(ECS Service)를 통해 작업 정의(컨테이너)를 관리할 수 있습니다. 
로드 밸런서와 연동하여 트랙픽을 다중 컨테이너에 분산할 수 있습니다. 
Auto Scailing을 사용하여 사용량에 기반하여 컨테이너 개수를 조절할 수 있습니다.&lt;/p&gt;

&lt;p&gt;이 문서에서는 서비스(ECS Service)를 구성하는 방법을 알아보겠습니다.&lt;/p&gt;

&lt;h2 id=&quot;사전-준비&quot;&gt;사전 준비&lt;/h2&gt;

&lt;p&gt;ECS 서비스를 구성하기 위해서 EBL를 생성합니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;EC2 Console에 접속 &amp;gt; 왼쪽 메뉴 &amp;gt; 로드 밸런싱 &amp;gt; 로드밸런서 선택&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;메인 화면 &amp;gt; &lt;code class=&quot;highlighter-rouge&quot;&gt;로드 밸런서 생성&lt;/code&gt; 버튼 선택&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;/blog/assets/images/cloud/aws/ecs/aws-ecs-prep-lb-01.png&quot; alt=&quot;&quot; width=&quot;30%&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;로드밸런서 유형 선택 &amp;gt; Application Load Balancer &amp;gt; &lt;code class=&quot;highlighter-rouge&quot;&gt;생성&lt;/code&gt; 버튼 선택
&lt;img src=&quot;/blog/assets/images/cloud/aws/ecs/aws-ecs-prep-lb-02.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;기본 구성 &amp;gt; 이름 &amp;gt; &lt;code class=&quot;highlighter-rouge&quot;&gt;cicd-demo&lt;/code&gt; 입력
&lt;img src=&quot;/blog/assets/images/cloud/aws/ecs/aws-ecs-prep-lb-03.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;리스너 &amp;gt; 기본 값인 &lt;code class=&quot;highlighter-rouge&quot;&gt;HTTP, 80&lt;/code&gt; 그대로 사용(애플리케이션 접속시 http를 사용하여 접속)
&lt;img src=&quot;/blog/assets/images/cloud/aws/ecs/aws-ecs-prep-lb-04.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;가용 영역 &amp;gt; VPC, 가용 영역 및 Subnet(Public) 선택 &amp;gt; &lt;code class=&quot;highlighter-rouge&quot;&gt;다음&lt;/code&gt; 버튼 선택
&lt;img src=&quot;/blog/assets/images/cloud/aws/ecs/aws-ecs-prep-lb-05.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;보안 설정은 변경 없이 &lt;code class=&quot;highlighter-rouge&quot;&gt;다음&lt;/code&gt; 버튼 선택
&lt;img src=&quot;/blog/assets/images/cloud/aws/ecs/aws-ecs-prep-lb-06.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;보안 그룹 구성&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;보안 그룹 할당 &amp;gt; 새 보안 그룹 생성 선택&lt;/li&gt;
      &lt;li&gt;보안 그룹 이름에 &lt;code class=&quot;highlighter-rouge&quot;&gt;cicd-demo&lt;/code&gt; 입력&lt;/li&gt;
      &lt;li&gt;설명에 &lt;code class=&quot;highlighter-rouge&quot;&gt;Allow http&lt;/code&gt; 입력&lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;유형 &lt;code class=&quot;highlighter-rouge&quot;&gt;HTTP&lt;/code&gt; 선택 &amp;gt; &lt;code class=&quot;highlighter-rouge&quot;&gt;다음&lt;/code&gt; 버튼 선택&lt;/p&gt;

        &lt;p&gt;&lt;img src=&quot;/blog/assets/images/cloud/aws/ecs/aws-ecs-prep-lb-07.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;대상 그룹&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;대상 그룹 &amp;gt; 새 대상 그룹 선택&lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;이름 &lt;code class=&quot;highlighter-rouge&quot;&gt;cicd-demo-service&lt;/code&gt; 입력&lt;/p&gt;

        &lt;p&gt;&lt;img src=&quot;/blog/assets/images/cloud/aws/ecs/aws-ecs-prep-lb-08.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;상태 검사&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;고급 상태 검사 설정 확장&lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;포트 &amp;gt; 재정의 선택 &amp;gt; &lt;code class=&quot;highlighter-rouge&quot;&gt;8080&lt;/code&gt; 입력(작업 정의에서 컨테이너 포트를 8080으로 지정)&lt;/p&gt;

        &lt;p&gt;&lt;img src=&quot;/blog/assets/images/cloud/aws/ecs/aws-ecs-prep-lb-09.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;대상 등록은 설정 변경 없이 &lt;code class=&quot;highlighter-rouge&quot;&gt;다음&lt;/code&gt; 버튼 선택
&lt;img src=&quot;/blog/assets/images/cloud/aws/ecs/aws-ecs-prep-lb-10.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;전체적으로 검토 &amp;gt; &lt;code class=&quot;highlighter-rouge&quot;&gt;생성&lt;/code&gt; 버튼 선택
&lt;img src=&quot;/blog/assets/images/cloud/aws/ecs/aws-ecs-prep-lb-11.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;서비스-생성하기&quot;&gt;서비스 생성하기&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;ECS Console에 접속 &amp;gt; 왼쪽 메뉴 &amp;gt; Amazon ECS &amp;gt; 클러스터 선택&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;클러스터 리스트 &amp;gt; &lt;code class=&quot;highlighter-rouge&quot;&gt;cicd-demo&lt;/code&gt; 선택&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;서비스 탭 &amp;gt; &lt;code class=&quot;highlighter-rouge&quot;&gt;생성&lt;/code&gt; 버튼 선택&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;/blog/assets/images/cloud/aws/ecs/aws-ecs-service-01.png&quot; alt=&quot;&quot; width=&quot;40%&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;서비스 구성&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;시작 유형 &amp;gt; FARGATE 선택&lt;/li&gt;
      &lt;li&gt;서비스 이름 &amp;gt; cicd-demo 입력&lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;작업 개수 &amp;gt; 2 입력&lt;/p&gt;

        &lt;p&gt;&lt;a href=&quot;/blog/assets/images/cloud/aws/ecs/aws-ecs-service-02.png&quot;&gt;&lt;/a&gt;&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Deployments &amp;gt; Rolling Update 선택 &amp;gt; &lt;code class=&quot;highlighter-rouge&quot;&gt;다음&lt;/code&gt; 버튼 선택
&lt;img src=&quot;/blog/assets/images/cloud/aws/ecs/aws-ecs-service-03.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

    &lt;p class=&quot;tip-title&quot;&gt;참고&lt;/p&gt;
    &lt;p class=&quot;tip-content&quot;&gt;
  - Rolling Update는 기존 버전의 인스턴스를 순차적으로 새로운 버전으로 업데이트하는 방식입니다.
  새로운 인스턴스를 생성하지 않기 때문에 비용 효율적입니다.&lt;br /&gt;

  - Blue/green deployment는 기존 버전의 인스턴스만큼 새로운 버전의 인스턴스를 배포합니다.
  새로운 버전을 테스트하고 트래픽을 일시에 기존 버전에서 새로운 버전으로 이동할 수 있습니다.
  새로운 인스턴스를 기존 버전만큼 생성해야하므로 비용면에서 상대적으로 비효율적입니다.
  &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;네트워크 구성 &amp;gt; VPC 및 보안 그룹&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;클러스터 VPC &amp;gt; 컨테이너가 위치할 VPC를 선택&lt;/li&gt;
      &lt;li&gt;서브넷 &amp;gt; 컨테이너가 위치할 서브넷을 선택(이 문서에서는 Private 서브넷을 기준으로 작성함)&lt;/li&gt;
      &lt;li&gt;보안 그룹 &amp;gt; 편집 선택 &amp;gt; 보안 그룹 구성&lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;자동 할당 퍼블릭 IP &amp;gt; DISABLED 선택&lt;/p&gt;

        &lt;p&gt;&lt;img src=&quot;/blog/assets/images/cloud/aws/ecs/aws-ecs-service-04-01.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

        &lt;p class=&quot;warning-title&quot;&gt;경고&lt;/p&gt;
        &lt;p class=&quot;warning-content&quot;&gt;
  - 자동 할당 퍼블릭 IP를 DISABLED로 선택할 경우 컨테이너에 퍼블릭 IP가 할당되지 않습니다.
  컨테이너에서 외부와의 통신을 하려면 컨테이너가 위치한 Private 서브넷이 외부와 통신할 수 있는 NAT와 연결되어야 합니다.&lt;br /&gt;
  - 자동 할당 퍼블릭 IP를 ENABLED로 선택할 경우 컨테이너에 퍼블릭 IP가 할당됩니다.
  컨테이너는 Public 서브넷에 위치하고 해당 서브넷은 IGW(Internet Gateway)와 연결되어 있어야 합니다.
  &lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;보안 그룹 구성&lt;/p&gt;

        &lt;ul&gt;
          &lt;li&gt;할당된 보안 그룹 &amp;gt; 새 보안 그룹 생성 선택&lt;/li&gt;
          &lt;li&gt;보안 그룹 이름 &amp;gt; cicd-demo-service 입력&lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;인바운드 규칙 &amp;gt; 유형에서 Custom TCP 선택 &amp;gt; 포트 범위 8080 입력(로드밸런서에서 컨테이너의 8080 포트로의 인바운드 트래픽)&lt;/p&gt;

            &lt;p&gt;&lt;img src=&quot;/blog/assets/images/cloud/aws/ecs/aws-ecs-service-04-02.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Elastic Load Balancing&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;ELB 유형 &amp;gt; Application Load Balancer 선택&lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;ELB 이름 &amp;gt; cicd-demo 선택(사전 준비에서 생성)&lt;/p&gt;

        &lt;p&gt;&lt;img src=&quot;/blog/assets/images/cloud/aws/ecs/aws-ecs-service-05.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;로드를 밸런싱할 컨테이너&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;cicd-demo:8080:8080 선택(작업 정의에서 생성) &amp;gt; ELB에 추가 버튼 선택&lt;/p&gt;

        &lt;p&gt;&lt;img src=&quot;/blog/assets/images/cloud/aws/ecs/aws-ecs-service-06-01.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;리스너 포트 &amp;gt; 80:HTTP 선택(사전 준비에서 생성)&lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;대상 그룹 이름 &amp;gt; cicd-demo-service 선택&lt;/p&gt;

        &lt;p&gt;&lt;img src=&quot;/blog/assets/images/cloud/aws/ecs/aws-ecs-service-06-02.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;다른 설정은 기본 설정을 사용 &amp;gt; 다음 단계 버튼 선택
&lt;img src=&quot;/blog/assets/images/cloud/aws/ecs/aws-ecs-service-07.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;서비스 Auto Scaling은 사용하지 않음 &amp;gt; 다음 단계 선택
&lt;img src=&quot;/blog/assets/images/cloud/aws/ecs/aws-ecs-service-08.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;서비스 검토를 전반적으로 하고 생성하기 버튼 선택해서 서비스 생성 완료
&lt;img src=&quot;/blog/assets/images/cloud/aws/ecs/aws-ecs-service-09.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;서비스-확인&quot;&gt;서비스 확인&lt;/h2&gt;

&lt;p&gt;이제 서비스가 정상적으로 구성되었는지 확인해보겠습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;ECS Console에 접속 &amp;gt; 왼쪽 메뉴 &amp;gt; Amazon ECS &amp;gt; 클러스터 선택&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;클러스터 리스트 &amp;gt; &lt;code class=&quot;highlighter-rouge&quot;&gt;cicd-demo&lt;/code&gt; 선택&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;서비스 탭 선택 &amp;gt; 상태가 Active인지 확인
&lt;img src=&quot;/blog/assets/images/cloud/aws/ecs/aws-ecs-service-10.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;작업 탭 선택 &amp;gt; 마지막/원하는 상태가 Running인지 확인
&lt;img src=&quot;/blog/assets/images/cloud/aws/ecs/aws-ecs-service-11.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;EC2 Console에 접속 &amp;gt; 왼쪽 메뉴 &amp;gt; 로드 밸런싱 &amp;gt; 로드밸런서 선택&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;로드밸런서 리스트 &amp;gt; &lt;code class=&quot;highlighter-rouge&quot;&gt;cicd-demo&lt;/code&gt; 선택&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;대상 탭 선택 &amp;gt; 등록된 대상 &amp;gt; 상태가 healthy인지 확인
&lt;img src=&quot;/blog/assets/images/cloud/aws/ecs/aws-ecs-service-12.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;설명 탭 선택 &amp;gt; DNS 이름 복사
&lt;img src=&quot;/blog/assets/images/cloud/aws/ecs/aws-ecs-service-13.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;웹 브라우저 &amp;gt; 복사한 DNS 이름 붙여넣고 접속 &amp;gt; 서비스 정상 접속 확인
&lt;img src=&quot;/blog/assets/images/cloud/aws/ecs/aws-ecs-service-14.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;bluegreen-deployment선택&quot;&gt;Blue/green deployment(선택)&lt;/h2&gt;

&lt;p&gt;위 과정에서는 서비스 생성 시 deployment 방식을 Rolling Update로 선택했습니다.&lt;/p&gt;

&lt;p&gt;Blue/green deployment를 활용하는 방법을 살펴보겠습니다.&lt;/p&gt;

&lt;h3 id=&quot;사전-준비-1&quot;&gt;사전 준비&lt;/h3&gt;

&lt;p&gt;Blue/green deployment 방식으로 서비스를 생성하는 경우 CodeDeploy에 애플리케이션 및 배포 그룹이 자동 생성됩니다.&lt;/p&gt;

&lt;p&gt;이를 위해 CodeDeploy 서비스 권한이 있는 IAM 역할 생성이 필요합니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;IAM Console에 접속 &amp;gt; 왼쪽 메뉴 &amp;gt; AWS Account &amp;gt; 역할 선택&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;메인 화면 &amp;gt; &lt;code class=&quot;highlighter-rouge&quot;&gt;역할 만들기&lt;/code&gt; 버튼 선택
&lt;img src=&quot;/blog/assets/images/cloud/aws/ecs/aws-ecs-prep-bg-iam-01.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;신뢰할 수 있는 유형의 개체 선택 &amp;gt; AWS 서비스 선택
&lt;img src=&quot;/blog/assets/images/cloud/aws/ecs/aws-ecs-prep-bg-iam-02-01.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;이 역할을 사용할 서비스 선택 &amp;gt; CodeDeploy 선택 &amp;gt; CodeDeploy - ECS 선택 &amp;gt; 다음 버튼 선택
&lt;img src=&quot;/blog/assets/images/cloud/aws/ecs/aws-ecs-prep-bg-iam-02-02.png&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;/blog/assets/images/cloud/aws/ecs/aws-ecs-prep-bg-iam-02-03.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;설정 변경 없이 다음 버튼 선택
&lt;img src=&quot;/blog/assets/images/cloud/aws/ecs/aws-ecs-prep-bg-iam-03.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;설정 변경 없이 다음 버튼 선택
&lt;img src=&quot;/blog/assets/images/cloud/aws/ecs/aws-ecs-prep-bg-iam-04.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;역할 이름 &amp;gt; codedeploy-cicd-demo-role 입력 &amp;gt; 역할 만들기 선택
&lt;img src=&quot;/blog/assets/images/cloud/aws/ecs/aws-ecs-prep-bg-iam-05.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;서비스-생성&quot;&gt;서비스 생성&lt;/h3&gt;

&lt;p&gt;Blue/green deployment 방식으로 서비스를 생성하는 경우 Rolling Update 방식과 아래 과정만 다릅니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Deployments
    &lt;ul&gt;
      &lt;li&gt;Deployment type &amp;gt; Blue/green deployment 선택&lt;/li&gt;
      &lt;li&gt;Service role for CodeDeploy &amp;gt; &lt;code class=&quot;highlighter-rouge&quot;&gt;다음&lt;/code&gt; 버튼 선택
  &lt;img src=&quot;/blog/assets/images/cloud/aws/ecs/aws-ecs-service-bg-01.png&quot; alt=&quot;&quot; /&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Additional configuration
    &lt;ul&gt;
      &lt;li&gt;Target group 1 name &amp;gt; cicd-demo-service 선택&lt;/li&gt;
      &lt;li&gt;Target group 2 name &amp;gt; 새로 생성 선택 &amp;gt; cicd-demo-service-green 입력&lt;/li&gt;
      &lt;li&gt;Target group 2 protocol &amp;gt; HTTP 선택
  &lt;img src=&quot;/blog/assets/images/cloud/aws/ecs/aws-ecs-service-bg-02.png&quot; alt=&quot;&quot; /&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;서비스-확인-1&quot;&gt;서비스 확인&lt;/h3&gt;

&lt;p&gt;서비스 확인 방법도 Rolling Update와 동일합니다.&lt;/p&gt;

&lt;p&gt;다른 점은 Blue/green deployment 방식으로 서비스를 생성하는 경우 CodeDeploy에 애플리케이션 및 배포 그룹이 자동 생성됩니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;CodeDeploy console 접속 &amp;gt; 왼쪽 메뉴의 애플리케이션 선택&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;애플리케이션 리스트 &amp;gt; AppECS-cicd-demo-cicd-demo 선택 
&lt;img src=&quot;/blog/assets/images/cloud/aws/ecs/aws-ecs-service-bg-03.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;배포 그룹 리스트 &amp;gt; DgpECS-cicd-demo-cicd-demo 선택 
&lt;img src=&quot;/blog/assets/images/cloud/aws/ecs/aws-ecs-service-bg-04.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;배포 그룹 확인
&lt;img src=&quot;/blog/assets/images/cloud/aws/ecs/aws-ecs-service-bg-05-01.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>sj</name></author><category term="aws" /><category term="container" /><category term="awsecs" /><category term="awsecsservice" /><category term="awsecsfargate" /><summary type="html">AWS에서 ECS(Elastic Container Service)의 서비스(ECS Service)를 통해 작업 정의(컨테이너)를 관리할 수 있습니다. 로드 밸런서와 연동하여 트랙픽을 다중 컨테이너에 분산할 수 있습니다. Auto Scailing을 사용하여 사용량에 기반하여 컨테이너 개수를 조절할 수 있습니다.</summary></entry></feed>